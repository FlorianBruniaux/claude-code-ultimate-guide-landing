# ═══════════════════════════════════════════════════════════════
# Claude Code Quiz - Human-Readable Format
# ═══════════════════════════════════════════════════════════════

Total Questions: 256
Categories: 15

## Table of Contents

  AI Ecosystem: 13 questions
  Advanced Patterns: 29 questions
  Agents: 18 questions
  Architecture Internals: 15 questions
  Commands: 12 questions
  Core Concepts: 18 questions
  Hooks: 16 questions
  Learning with AI: 17 questions
  MCP Servers: 20 questions
  Memory & Settings: 19 questions
  Privacy & Observability: 11 questions
  Quick Start: 18 questions
  Reference: 20 questions
  Security Hardening: 12 questions
  Skills: 18 questions

══════════════════════════════════════════════════════════════════════


######################################################################
# CATEGORY: AI ECOSYSTEM
# 13 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the main philosophy behind using complementary AI tools with Claude Code?

OPTIONS:
  [A] Replace Claude Code with better tools
  [B] Augmentation, not replacement - chain the right tool for each step ← ✓ CORRECT
  [C] Use as many tools as possible simultaneously
  [D] Avoid using Claude Code for coding tasks

ANSWER: B

EXPLANATION:
  The philosophy is "augmentation, not replacement."
  
  Claude Code excels at contextual reasoning and implementation, but has gaps:
  - No real-time web search with source verification
  - No image generation
  - No PowerPoint/slide generation
  - No audio synthesis
  
  The goal is to chain the right tool for each step of your workflow.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you use Perplexity instead of Claude Code?

OPTIONS:
  [A] When implementing features in your codebase
  [B] When you need deep research with 100+ verified sources ← ✓ CORRECT
  [C] When editing multiple files
  [D] When running tests

ANSWER: B

EXPLANATION:
  Perplexity excels at research with verified sources.
  
  Use Perplexity for:
  - "What's the latest API for X?" (real-time info)
  - "Compare 5 libraries for auth" (sourced comparisons)
  - Deep Research mode synthesizes 100+ sources
  
  Use Claude Code for:
  - Implementation in your codebase
  - Contextual code explanation
  - Multi-file editing
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended Research-to-Code pipeline?

OPTIONS:
  [A] Claude Code -> Perplexity -> Implementation
  [B] Perplexity Deep Research -> Export spec.md -> Claude Code implements ← ✓ CORRECT
  [C] Google Search -> Copy code -> Paste in project
  [D] Ask Claude Code to search the web first

ANSWER: B

EXPLANATION:
  The Research-to-Code pipeline:
  
  1. PERPLEXITY (Deep Research)
     - Research best practices with sources
     - Output: 2000-word spec with citations
  
  2. Export as spec.md
  
  3. CLAUDE CODE
     - "Implement following spec.md"
     - Output: Working implementation with tests
  
  This ensures implementation is based on verified, current information.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-004          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which tool is best for converting a UI screenshot to React code?

OPTIONS:
  [A] Perplexity
  [B] Claude Code directly
  [C] Gemini 2.5 Pro -> then Claude Code for refinement ← ✓ CORRECT
  [D] NotebookLM

ANSWER: C

EXPLANATION:
  Gemini 2.5 Pro excels at visual understanding:
  
  Visual-to-Code Pipeline:
  1. GEMINI: Upload screenshot -> Get JSX + Tailwind (90%+ fidelity)
  2. CLAUDE CODE: Refine for your project
     - Add TypeScript types
     - Connect to your components
     - Integrate with your state management
  
  Claude Code alone has limited image understanding compared to Gemini.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-005          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which tool should you use to create PowerPoint presentations from code documentation?

OPTIONS:
  [A] Claude Code
  [B] Perplexity
  [C] Kimi (Moonshot AI) ← ✓ CORRECT
  [D] Gemini

ANSWER: C

EXPLANATION:
  Kimi (kimi.ai) from Moonshot AI specializes in PPTX generation:
  
  Features:
  - Native PPTX export (actual slides, not markdown)
  - 128K+ token context (entire codebases)
  - Code-aware layouts with syntax highlighting
  - Excellent for stakeholder decks from technical content
  
  Workflow: Claude Code generates summary -> Kimi creates presentation
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-006          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is NotebookLM's unique feature for developer onboarding?

OPTIONS:
  [A] Code execution
  [B] Audio Overview - generates podcast-style explanations from docs ← ✓ CORRECT
  [C] Real-time collaboration
  [D] Git integration

ANSWER: B

EXPLANATION:
  NotebookLM's Audio Overview feature:
  
  - Upload 50+ documentation files
  - Generates 10-15 minute "podcast"
  - Two AI hosts discuss your codebase
  - Perfect for onboarding or reviewing large systems
  
  Workflow:
  1. Export docs to combined-docs.md
  2. Upload to NotebookLM
  3. Generate Audio Overview
  4. Listen during commute
  5. Return to Claude Code with deeper understanding
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-007          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the complete workflow pipeline, what is the correct order of phases?

OPTIONS:
  [A] Implementation -> Planning -> Delivery
  [B] Planning (Perplexity/Gemini/NotebookLM) -> Implementation (Claude Code) -> Delivery (Kimi) ← ✓ CORRECT
  [C] Delivery -> Planning -> Implementation
  [D] All tools simultaneously

ANSWER: B

EXPLANATION:
  The complete pipeline has 3 phases:
  
  PLANNING PHASE:
  - Perplexity: Deep Research -> spec.md
  - Gemini: Diagram Analysis -> mermaid + plan
  - NotebookLM: Doc Synthesis -> audio overview
  
  IMPLEMENTATION PHASE:
  - Claude Code: Multi-file implementation
  - IDE + Copilot: Inline autocomplete
  
  DELIVERY PHASE:
  - Claude Code: PR description, release notes
  - Kimi: Stakeholder deck (presentation.pptx)
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-008          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is v0.dev best used for in the AI ecosystem?

OPTIONS:
  [A] Backend API development
  [B] Database queries
  [C] Rapid UI prototyping with Shadcn/Tailwind ← ✓ CORRECT
  [D] Security auditing

ANSWER: C

EXPLANATION:
  v0.dev excels at rapid UI prototyping:
  
  - Generates React + Shadcn + Tailwind components
  - Live preview in browser
  - Quick iteration on UI designs
  
  Workflow:
  1. v0: Prompt -> Get component preview
  2. Export code
  3. Claude Code: Adapt for your project
     - Add TypeScript types
     - Connect to your APIs
     - Integrate with your design system
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How does Claude WebSearch compare to Perplexity Pro for research?

OPTIONS:
  [A] Claude WebSearch has more sources (100+)
  [B] They are identical in functionality
  [C] Claude WebSearch: 5-10 sources, quick lookups. Perplexity Pro: 100+ sources, comprehensive research ← ✓ CORRECT
  [D] Perplexity cannot access real-time data

ANSWER: C

EXPLANATION:
  Comparison:
  
  | Feature | Claude WebSearch | Perplexity Pro |
  |---------|-----------------|----------------|
  | Source count | ~5-10 | 100+ (Deep Research) |
  | Source verification | Basic | Full citations |
  | Best for | Quick lookups | Comprehensive research |
  | Cost | Included | $20/month |
  
  Recommendation: Use Claude WebSearch for quick factual checks.
  Use Perplexity Deep Research before significant implementations.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-010          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Minimal Stack' monthly cost recommendation for AI tools?

OPTIONS:
  [A] $200+/month - all Pro subscriptions
  [B] $40-70/month - Claude Code + Perplexity Pro, free tiers for rest ← ✓ CORRECT
  [C] $0 - only free tiers
  [D] $500+/month - enterprise plans

ANSWER: B

EXPLANATION:
  Recommended subscription stacks:
  
  Minimal Stack ($40-70/month):
  - Claude Code (pay-per-use): $20-50
  - Perplexity Pro: $20
  - Everything else: Free tiers (NotebookLM, Kimi, Gemini free)
  
  Balanced Stack ($80-110/month):
  - Add Gemini Advanced ($20) and Cursor Pro ($20)
  
  Cost optimization tips:
  - Use Haiku for simple tasks
  - Batch research sessions in Perplexity
  - Check context usage regularly (/status)
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What cost savings does the Claude Code to LM Studio bridge provide?

OPTIONS:
  [A] 20-30% savings on API costs
  [B] 50% savings but slower execution
  [C] 80-90% savings by planning with Opus then executing free with local LLM ← ✓ CORRECT
  [D] No savings but better privacy

ANSWER: C

EXPLANATION:
  The Claude Code to LM Studio bridge provides 80-90% cost savings. Strategy: use Opus for planning phase (~$0.50-2 per session) then execute implementation with a free local LLM via LM Studio. The bridge script translates Claude's plan into local LLM instructions. Trade-off: local LLMs are less capable but free.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-012          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 documented external orchestration systems for multi-agent Claude Code?

OPTIONS:
  [A] LangChain, AutoGPT, CrewAI
  [B] Vercel AI SDK, Fly.io Machines, Railway
  [C] Gas Town (Steve Yegge), multiclaude (dlorenc), agent-chat (Justin Abrahms) ← ✓ CORRECT
  [D] Kubernetes, Docker Compose, Terraform

ANSWER: C

EXPLANATION:
  Three documented external orchestration systems:
  
  1. **Gas Town** (Steve Yegge) - Multi-agent coordination with shared context
  2. **multiclaude** (dlorenc) - Parallel Claude Code instances with task distribution
  3. **agent-chat** (Justin Abrahms) - Inter-agent communication protocol
  
  These are community-built tools, not official Anthropic products. Each solves multi-agent coordination differently.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-013          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What 3 areas should sub-agents audit when evaluating a skeleton project before forking?

OPTIONS:
  [A] Performance, Cost, Scalability
  [B] UI, API, Database
  [C] Security, Architecture, Developer Experience (DX) ← ✓ CORRECT
  [D] Tests, Documentation, CI/CD

ANSWER: C

EXPLANATION:
  Skeleton project evaluation uses 3 specialized sub-agents:
  
  1. **Security** - Audit dependencies, secrets management, auth patterns, known vulnerabilities
  2. **Architecture** - Evaluate code organization, patterns, scalability, maintainability
  3. **Developer Experience (DX)** - Check setup complexity, documentation quality, tooling, onboarding friction
  
  Each agent produces a score and recommendations before the fork decision.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: ADVANCED PATTERNS
# 29 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-001          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the three components of 'The Trinity' pattern?

OPTIONS:
  [A] Git, VSCode, Terminal
  [B] Plan Mode, Extended Thinking, Sequential Thinking ← ✓ CORRECT
  [C] Serena, Context7, Playwright
  [D] Agent, Skill, Command

ANSWER: B

EXPLANATION:
  The Trinity is the most powerful Claude Code pattern combining:
  
  1. **Plan Mode** - Safe exploration without changes
  2. **Extended Thinking** - Deep analysis (enabled by default in Opus 4.5)
  3. **Sequential Thinking (MCP)** - Structured multi-step reasoning
  
  Combined, these provide maximum understanding before taking action.
  Use for architecture decisions, complex debugging, and legacy modernization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-002          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you toggle thinking mode in Claude Code (Opus 4.5+)?

OPTIONS:
  [A] Use 'ultrathink' keyword in your prompt
  [B] Alt+T (or Option+T on macOS) ← ✓ CORRECT
  [C] --think CLI flag
  [D] /thinking command

ANSWER: B

EXPLANATION:
  With Opus 4.5 (v2.0.67+), thinking mode is enabled by default at maximum budget.
  
  **Controlling Thinking Mode:**
  | Method | Action | Persistence |
  |--------|--------|-------------|
  | **Alt+T** | Toggle on/off | Session |
  | **/config** | Enable/disable globally | Permanent |
  
  **Note**: Keywords like "ultrathink" are now cosmetic only - they no longer control thinking behavior.
  
  Use Alt+T to disable thinking for simple tasks (faster, cheaper).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What CLI flag runs Claude Code without interactive prompts for CI/CD?

OPTIONS:
  [A] --ci
  [B] --headless ← ✓ CORRECT
  [C] --batch
  [D] --automated

ANSWER: B

EXPLANATION:
  The `--headless` flag runs Claude Code without interactive prompts:
  
  ```bash
  # Basic headless execution
  claude --headless "Run the tests and report results"
  
  # With timeout
  claude --headless --timeout 300 "Build the project"
  ```
  
  Essential for CI/CD integration, automated pipelines, and scripted workflows.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you pipe content to Claude Code with a prompt?

OPTIONS:
  [A] claude | cat file.txt -p 'analyze'
  [B] cat file.txt | claude -p 'analyze this code' ← ✓ CORRECT
  [C] claude < file.txt --prompt 'analyze'
  [D] file.txt > claude -p 'analyze'

ANSWER: B

EXPLANATION:
  Use standard Unix piping with the `-p` flag:
  
  ```bash
  cat file.txt | claude -p 'analyze this code'
  git diff | claude -p 'explain these changes'
  npm test 2>&1 | claude -p 'summarize test failures'
  ```
  
  This enables powerful shell integration for automated code analysis.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-005          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Rev the Engine' pattern?

OPTIONS:
  [A] Running tests in parallel
  [B] Multiple rounds of write-critique-improve cycles ← ✓ CORRECT
  [C] Restarting Claude Code between tasks
  [D] Using higher compute models

ANSWER: B

EXPLANATION:
  The "Rev the Engine" pattern uses multiple rounds of critique for quality:
  
  ```
  Round 1: [Initial implementation]
  Critique: [What's wrong]
  Improvement: [Better version]
  
  Round 2: [Improved implementation]
  Critique: [What's still wrong]
  Improvement: [Even better version]
  
  Round 3: [Final implementation]
  Final check: [Verification]
  ```
  
  Typically 3 rounds are recommended for quality work.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-006          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What output format flag gets structured JSON from Claude for scripting?

OPTIONS:
  [A] --format json
  [B] --output-format json ← ✓ CORRECT
  [C] --json
  [D] --structured

ANSWER: B

EXPLANATION:
  Use `--output-format` to control response format:
  
  | Format | Use Case |
  |--------|----------|
  | `text` | Human-readable output (default) |
  | `json` | Machine-parseable structured data |
  | `stream-json` | Real-time streaming for large outputs |
  
  Example:
  ```bash
  git log --oneline -10 | claude -p 'Categorize commits' --output-format json
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-007          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Vibe Coding' according to the guide?

OPTIONS:
  [A] Coding while listening to music
  [B] Rapid prototyping through natural conversation before committing to implementation ← ✓ CORRECT
  [C] Using AI to generate random code
  [D] Coding in a relaxed environment

ANSWER: B

EXPLANATION:
  Vibe Coding is rapid prototyping through natural conversation.
  
  When to vibe code:
  - Early exploration: Testing if an approach works
  - Proof of concept: Quick validation before full implementation
  - Learning: Understanding a new library or pattern
  
  Rules:
  - No production code - exploration only
  - Throw away freely
  - Focus on learning
  - Signal clearly: "This is vibe code, not for production"
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-008          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the Verify Gate Pattern before creating a PR?

OPTIONS:
  [A] Just run tests
  [B] Build -> Lint -> Test -> Type-check -> THEN create PR ← ✓ CORRECT
  [C] Create PR first, then fix issues
  [D] Manual review only

ANSWER: B

EXPLANATION:
  The Verify Gate Pattern ensures all checks pass before PR creation:
  
  ```
  Build -> Lint -> Test -> Type-check -> THEN create PR
  ```
  
  If ANY step fails:
  - Stop immediately
  - Report what failed and why
  - Suggest fixes
  - Do NOT proceed to PR creation
  
  This prevents wasted CI cycles and review time.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the key insight of 'Todo as Instruction Mirrors'?

OPTIONS:
  [A] Todos are just for tracking
  [B] What you write as a todo becomes Claude's instruction ← ✓ CORRECT
  [C] Todos should be vague for flexibility
  [D] Always use bullet points

ANSWER: B

EXPLANATION:
  The Mirror Principle: What you write as a todo becomes Claude's instruction.
  
  Bad (vague todo -> vague execution):
  "Fix the bug"
  
  Good (specific todo -> precise execution):
  "Fix null pointer in getUserById when user not found - return null instead of throwing"
  
  Well-crafted todos guide Claude's execution with precision.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-010          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  According to 'Continuous Improvement Mindset', what should you ask after every manual intervention?

OPTIONS:
  [A] Was this my fault?
  [B] How can I improve the process so this error can be avoided next time? ← ✓ CORRECT
  [C] Who is responsible for this?
  [D] Should I use a different AI?

ANSWER: B

EXPLANATION:
  After every manual intervention, ask:
  "How can I improve the process so this error or manual fix can be avoided next time?"
  
  The improvement pipeline:
  1. Can a linting rule catch it? -> Add lint rule
  2. Can it go in conventions/docs? -> Add to CLAUDE.md or ADRs
  3. Neither? -> Accept as edge case
  
  The meta-skill: instead of fixing code, fix the system that produces the code.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-011          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a Skeleton Project?

OPTIONS:
  [A] A project with no code
  [B] A minimal, working template that establishes patterns before full implementation ← ✓ CORRECT
  [C] A deprecated project
  [D] A project outline document

ANSWER: B

EXPLANATION:
  A skeleton project is a minimal, working template that establishes patterns.
  
  Skeleton principles:
  1. **It must run**: `pnpm dev` works from day 1
  2. **One complete vertical**: Full stack for one feature
  3. **Patterns, not features**: Shows HOW, not WHAT
  4. **Minimal dependencies**: Only what's needed
  
  Progression: Skeleton (Day 1) -> MVP (Week 1) -> Full (Month 1)
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is OpusPlan mode?

OPTIONS:
  [A] Using only Opus for everything
  [B] Opus for planning, Sonnet for execution ← ✓ CORRECT
  [C] A special debugging mode
  [D] Planning without AI

ANSWER: B

EXPLANATION:
  OpusPlan mode combines model strengths:
  - **Planning**: Opus for high-level thinking
  - **Execution**: Sonnet for implementation
  
  This provides strategic thinking + cost-effective execution.
  
  ```bash
  /model opusplan
  Shift+Tab x 2  # Enter Plan Mode (Opus)
  # Design architecture...
  Shift+Tab      # Exit Plan Mode (Sonnet)
  # Implement the plan...
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-013          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you NOT use --dangerously-skip-permissions?

OPTIONS:
  [A] In CI/CD pipelines
  [B] On production systems or sensitive codebases ← ✓ CORRECT
  [C] For automated testing
  [D] In Docker containers

ANSWER: B

EXPLANATION:
  Never use `--dangerously-skip-permissions` on production systems or sensitive codebases.
  
  Safe usage:
  - CI/CD pipelines with isolated environments
  - Automated testing with limited scope
  - Development containers
  
  Unsafe usage:
  - Production systems
  - Codebases with secrets
  - Environments with sensitive data
  
  The flag bypasses all permission prompts, creating security risks.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What prompt format does the guide recommend for effective requests?

OPTIONS:
  [A] Simple natural language
  [B] WHAT, WHERE, HOW, VERIFY ← ✓ CORRECT
  [C] Subject, Body, Footer
  [D] Title, Description, Acceptance Criteria

ANSWER: B

EXPLANATION:
  The recommended prompt format:
  
  - **WHAT**: Concrete deliverable
  - **WHERE**: File paths/locations
  - **HOW**: Constraints/approach
  - **VERIFY**: Success criteria
  
  Example:
  ```
  WHAT: Add input validation to the login form
  WHERE: src/components/LoginForm.tsx, src/schemas/auth.ts
  HOW: Use Zod schema validation, display errors inline
  VERIFY: Empty email shows error, invalid format shows error
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-015          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended learning progression for Claude Code?

OPTIONS:
  [A] Learn everything at once
  [B] Start with advanced features
  [C] Week 1: Basic commands -> Week 2: CLAUDE.md -> Week 3: Agents -> Month 2+: MCP servers ← ✓ CORRECT
  [D] Skip to MCP servers immediately

ANSWER: C

EXPLANATION:
  The guide recommends progressive learning:
  
  1. **Week 1**: Basic commands, context management
  2. **Week 2**: CLAUDE.md, permissions
  3. **Week 3**: Agents and commands
  4. **Month 2+**: MCP servers, advanced patterns
  
  Start with simple, low-risk tasks and build up complexity gradually.
  This avoids overwhelm and builds solid fundamentals.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-016          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What git workflow enables working on multiple features simultaneously with isolated contexts?

OPTIONS:
  [A] Git stash
  [B] Git worktrees ← ✓ CORRECT
  [C] Git branches only
  [D] Git submodules

ANSWER: B

EXPLANATION:
  Git worktrees create multiple working directories from the same repository.
  
  Benefits:
  - Work on multiple features simultaneously
  - Each worktree has independent Claude Code context
  - No need for stash/switch operations
  - Parallel testing while developing
  
  ```bash
  git worktree add ../myproject-hotfix hotfix
  git worktree add ../myproject-feature-a feature-a
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-017          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is SDD (Spec-Driven Development) and its key claim?

OPTIONS:
  [A] Speed-based Development - fastest approach
  [B] Spec-Driven Development - one well-structured iteration equals 8 unstructured ones ← ✓ CORRECT
  [C] Standard Driven Development - follows industry standards
  [D] Sequential Driven Development - linear workflow

ANSWER: B

EXPLANATION:
  SDD (Spec-Driven Development) means specifications BEFORE code. The key claim: one well-structured iteration equals 8 unstructured ones. CLAUDE.md IS your spec file. Best for APIs and contracts. High Claude fit (⭐⭐⭐).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-018          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What format does BDD (Behavior-Driven Development) use for test scenarios?

OPTIONS:
  [A] Arrange-Act-Assert
  [B] Given-When-Then (Gherkin) ← ✓ CORRECT
  [C] Setup-Execute-Verify
  [D] Input-Process-Output

ANSWER: B

EXPLANATION:
  BDD uses Given-When-Then format (Gherkin). BDD is beyond testing - it's a collaboration process: (1) Discovery with devs/business, (2) Formulation with examples, (3) Automation via Cucumber. Example: Given product with 0 stock → When customer attempts purchase → Then system refuses.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-019          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the three steps of the TDD cycle?

OPTIONS:
  [A] Plan-Develop-Test
  [B] Red-Green-Refactor ← ✓ CORRECT
  [C] Write-Run-Fix
  [D] Design-Code-Review

ANSWER: B

EXPLANATION:
  The classic TDD cycle: (1) Red - write failing test, (2) Green - minimal code to pass, (3) Refactor - clean up while tests stay green. With Claude: be explicit "Write FAILING tests that don't exist yet." TDD is a core workflow (⭐⭐⭐).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-020          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How many development methodologies are documented in the methodologies reference?

OPTIONS:
  [A] 5 methodologies
  [B] 10 methodologies
  [C] 15 methodologies ← ✓ CORRECT
  [D] 20 methodologies

ANSWER: C

EXPLANATION:
  15 methodologies organized in a 6-tier pyramid: Tier 1 (Strategic - BMAD), Tier 2 (Specification - SDD, Doc-Driven, Req-Driven, DDD), Tier 3 (Behavior - BDD, ATDD, CDD), Tier 4 (Feature - FDD, Context Engineering), Tier 5 (Implementation - TDD, Eval-Driven, Multi-Agent), Tier 6 (Optimization).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-021          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Context Engineering' as a methodology?

OPTIONS:
  [A] Engineering team context
  [B] Treating context as first-class design element: progressive disclosure, memory management, dynamic refresh ← ✓ CORRECT
  [C] Building context menus
  [D] Managing environment variables

ANSWER: B

EXPLANATION:
  Context Engineering treats context as a design element. Key concepts: Progressive Disclosure (let agent discover incrementally), Memory Management (conversation vs persistent memory), Dynamic Refresh (rewrite TODO list before response). High Claude fit (⭐⭐⭐) for long sessions.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-022          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 5 layers of 'Mechanic Stacking'?

OPTIONS:
  [A] Plan Mode, Extended Thinking, Rev the Engine, Split-Role, Permutation ← ✓ CORRECT
  [B] Plan Mode, Sequential Thinking, Context7, Serena, Playwright
  [C] CLAUDE.md, Plan Mode, Extended Thinking, MCP Servers, Hooks
  [D] Plan Mode, Extended Thinking, Rev the Engine, Multi-Agent, Hooks

ANSWER: A

EXPLANATION:
  Mechanic Stacking layers 5 techniques for maximum Claude Code power:
  
  1. **Plan Mode** - Safe exploration without changes
  2. **Extended Thinking** - Deep internal reasoning
  3. **Rev the Engine** - Progressive warm-up prompts
  4. **Split-Role** - Separate architect/implementer/reviewer
  5. **Permutation** - Systematic variation testing
  
  Each layer compounds the previous one's effectiveness.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-023          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a 'Permutation Framework' in Claude Code?

OPTIONS:
  [A] A/B testing of UI variants
  [B] CLAUDE.md-driven systematic variation testing: define dimensions, generate variants, implement, evaluate ← ✓ CORRECT
  [C] Random code generation for benchmarks
  [D] Automated regression test suite

ANSWER: B

EXPLANATION:
  A Permutation Framework uses CLAUDE.md to drive systematic variation testing. The workflow: define variation dimensions (e.g., algorithm choice, data structure, caching strategy), generate all combinations, implement each variant, evaluate with metrics. This ensures you explore the solution space methodically rather than picking the first approach.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-024          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What mental model describes the developer as an orchestrator of Claude instances?

OPTIONS:
  [A] Pipeline Manager
  [B] Agent Supervisor
  [C] You Are the Main Thread - CPU scheduler analogy where developer dispatches tasks to agents ← ✓ CORRECT
  [D] Task Router

ANSWER: C

EXPLANATION:
  "You Are the Main Thread" uses the CPU scheduler analogy: the developer is the main thread dispatching work to Claude instances (worker threads). You manage priorities, context switches, and synchronization. Key insight: you don't write code - you manage the agents that write code. This shifts the skill from coding to orchestration.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-025          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When task list items consistently diverge from actual work done, what does the guide recommend?

OPTIONS:
  [A] Delete the task list and start over
  [B] Add more granular detail to each task
  [C] Use divergence patterns as diagnostic: too broad = break down, too narrow = step back, wrong priorities = re-align with goals ← ✓ CORRECT
  [D] Ignore the divergence and continue

ANSWER: C

EXPLANATION:
  Task list divergence is diagnostic, not failure. Patterns reveal issues:
  
  - **Too broad** tasks → break down into smaller pieces
  - **Too narrow** tasks → step back and think bigger
  - **Wrong priorities** → re-align tasks with actual goals
  - **Consistent drift** → your mental model of the problem is wrong
  
  Use divergence as signal, not noise.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-026          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'occurrence rule' for claiming established patterns in code reviews?

OPTIONS:
  [A] >5 occurrences = established, 2-5 = emerging, <2 = not established
  [B] >10 occurrences = established, 3-10 = emerging, <3 = not established ← ✓ CORRECT
  [C] Based on file count, not occurrences
  [D] >20 occurrences = established, 5-20 = emerging, <5 = not established

ANSWER: B

EXPLANATION:
  Anti-hallucination safeguards for code reviews define the occurrence rule:
  
  - **>10 occurrences** = established pattern (safe to reference)
  - **3-10 occurrences** = emerging pattern (mention cautiously)
  - **<3 occurrences** = NOT an established pattern (don't claim it is)
  
  This prevents Claude from hallucinating "established conventions" from a few examples.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-027          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 specialized agents in multi-agent code review?

OPTIONS:
  [A] Security Reviewer, Performance Analyst, UX Reviewer
  [B] Linter, Type Checker, Test Runner
  [C] Consistency Agent, SOLID Agent, Defensive Code Auditor ← ✓ CORRECT
  [D] Junior Reviewer, Senior Reviewer, Architect Reviewer

ANSWER: C

EXPLANATION:
  Multi-agent PR review uses 3 specialized agents:
  
  1. **Consistency Agent** - Checks naming conventions, import patterns, code style adherence
  2. **SOLID Agent** - Reviews architectural principles, dependency injection, single responsibility
  3. **Defensive Code Auditor** - Validates error handling, input validation, edge cases
  
  Each agent has anti-hallucination safeguards (occurrence rule, file-scoped claims).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-028          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'comprehension debt' according to Addy Osmani's '80% Problem'?

OPTIONS:
  [A] Documentation debt - missing docs
  [B] Code you shipped but don't fully understand - distinct from technical debt ← ✓ CORRECT
  [C] Review debt - unreviewed PRs
  [D] Design debt - skipped design phase

ANSWER: B

EXPLANATION:
  Comprehension debt is code you shipped but don't fully understand. It's distinct from technical debt (code you understand but know is suboptimal). With AI-generated code, comprehension debt grows silently: you accept suggestions without deep understanding. The fix: always be able to explain WHY, not just WHAT.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-029          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the '4-step cycle' for CLAUDE.md as compounding memory (Boris Cherny)?

OPTIONS:
  [A] Write, Test, Deploy, Monitor
  [B] Plan, Execute, Review, Commit
  [C] Error, Rule, Read, Never repeated ← ✓ CORRECT
  [D] Ask, Implement, Validate, Ship

ANSWER: C

EXPLANATION:
  Boris Cherny's mental model for CLAUDE.md as compounding memory:
  
  1. **Error** - Claude makes a mistake
  2. **Rule** - You add a rule to CLAUDE.md preventing it
  3. **Read** - Claude reads CLAUDE.md on every session start
  4. **Never repeated** - The mistake never happens again
  
  Goal: never correct Claude twice for the same mistake. CLAUDE.md compounds over time.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: AGENTS
# 18 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are agents in Claude Code?

OPTIONS:
  [A] External software programs
  [B] Specialized AI personas for specific tasks that Claude can delegate to ← ✓ CORRECT
  [C] Human assistants
  [D] Automated scripts

ANSWER: B

EXPLANATION:
  Agents are specialized sub-processes (AI personas) that Claude can delegate tasks to. They encapsulate domain expertise, like a security reviewer knowing OWASP Top 10 or a backend architect understanding API design. Think of them as "expert consultants" - instead of explaining everything in your prompt, you invoke an agent that already has that expertise.
  

OFFICIAL DOC: https://code.claude.com/docs/en/agents

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where should custom agent files be stored?

OPTIONS:
  [A] ~/.claude/agents/
  [B] .claude/agents/ ← ✓ CORRECT
  [C] /agents/
  [D] .claude/commands/

ANSWER: B

EXPLANATION:
  Custom agent files should be stored in `.claude/agents/` within your project directory. They are markdown files with YAML frontmatter. For example: `.claude/agents/backend-architect.md`, `.claude/agents/code-reviewer.md`. These can be committed to version control to share with your team.
  

OFFICIAL DOC: https://code.claude.com/docs/en/agents

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What fields are REQUIRED in an agent's YAML frontmatter?

OPTIONS:
  [A] name, model, tools
  [B] name, description ← ✓ CORRECT
  [C] name, description, model, tools
  [D] name, role, skills

ANSWER: B

EXPLANATION:
  Only `name` and `description` are required in agent frontmatter. Optional fields include: model (sonnet default, opus, or haiku), tools (comma-separated list), skills (to inherit), and disallowedTools. The description is crucial - it determines when Claude auto-activates the agent, so make it clear and specific.
  

OFFICIAL DOC: https://code.claude.com/docs/en/agents

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the advantage of using agents over direct prompts?

OPTIONS:
  [A] Agents are faster
  [B] Agents encapsulate expertise so you don't need to explain everything each time ← ✓ CORRECT
  [C] Agents cost less
  [D] Agents can access more files

ANSWER: B

EXPLANATION:
  Agents encapsulate expertise. Without agents, you'd write: "Review this code for security issues, focusing on OWASP Top 10, checking for SQL injection, XSS, CSRF..." With agents: "Use the security-reviewer agent to audit this code." The agent already has that expertise, making your prompts shorter and more consistent.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which model should you use for agents performing complex architectural analysis?

OPTIONS:
  [A] haiku - for speed
  [B] sonnet - for balance
  [C] opus - for maximum reasoning ← ✓ CORRECT
  [D] Any model works equally well

ANSWER: C

EXPLANATION:
  Use opus for complex reasoning and architecture tasks. Model selection guidelines: haiku (fast, low cost) for quick tasks and simple changes; sonnet (balanced, default) for most tasks; opus (slow, high cost) for complex reasoning, architecture decisions, and critical security reviews. Match the model to the task's complexity.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-006          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Tool SEO' in agent design?

OPTIONS:
  [A] Making tools searchable online
  [B] Optimizing the description field to improve when Claude auto-activates the agent ← ✓ CORRECT
  [C] SEO for documentation
  [D] A marketing technique

ANSWER: B

EXPLANATION:
  Tool SEO optimizes the agent's description field to improve auto-activation. Techniques include: using "use PROACTIVELY" to encourage automatic activation, listing explicit trigger keywords, describing specific contexts, and adding short nicknames. A good description: "Security code reviewer - use PROACTIVELY when: reviewing auth code, analyzing API endpoints... Triggers: security, auth, vulnerability, OWASP"
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-007          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the best practice for agent design: specialization or generalization?

OPTIONS:
  [A] Create one generalist agent that does everything
  [B] Create specialized agents for each domain (security, testing, backend, etc.) ← ✓ CORRECT
  [C] Mix specialized and generalist agents
  [D] Avoid agents entirely

ANSWER: B

EXPLANATION:
  Always prefer specialization over generalization. Good: separate agents for backend-architect (API, database, performance), security-reviewer (OWASP, auth, encryption), test-engineer (test strategy, coverage, TDD). Bad: one full-stack-expert that "does everything (poorly)". Specialized agents have focused context and domain-specific expertise.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-008          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How can agents inherit knowledge from skills?

OPTIONS:
  [A] By copying skill content into the agent
  [B] Using the 'skills' field in the frontmatter ← ✓ CORRECT
  [C] Skills and agents cannot be combined
  [D] By importing skill files

ANSWER: B

EXPLANATION:
  Agents inherit skills using the `skills` field in frontmatter. For example: `skills: [security-guardian]`. This composes expertise without duplication - instead of copying OWASP knowledge into every security-related agent, they all inherit from the security-guardian skill. This follows DRY principles for knowledge organization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-009          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the '7-Parallel-Task Method'?

OPTIONS:
  [A] Running 7 Claude instances simultaneously
  [B] Launching 7 specialized sub-agents in parallel to implement complete features ← ✓ CORRECT
  [C] A debugging technique
  [D] A code review checklist

ANSWER: B

EXPLANATION:
  The 7-Parallel-Task Method launches 7 specialized sub-agents in parallel: 1) Components, 2) Styles, 3) Tests, 4) Types, 5) Hooks, 6) Integration, 7) Config. All run in parallel, then results are consolidated. This dramatically speeds up feature implementation by parallelizing independent work streams.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-010          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended agent weight for frequently-used tasks?

OPTIONS:
  [A] Heavy (25K+ tokens) for thoroughness
  [B] Medium (10-15K tokens) for balance
  [C] Lightweight (<3K tokens) for speed ← ✓ CORRECT
  [D] Weight doesn't matter

ANSWER: C

EXPLANATION:
  Use lightweight agents (<3K tokens, <1s init time) for frequent tasks and workers. Golden Rule: "A lightweight agent used 100x > A heavy agent used 10x." Agent weight categories: Lightweight (<3K tokens) for frequent tasks, Medium (10-15K) for analysis/reviews, Heavy (25K+) for architecture/full audits. Match weight to task frequency.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-011          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In multi-agent orchestration, what model combination is recommended?

OPTIONS:
  [A] Opus everywhere for quality
  [B] Haiku everywhere for cost savings
  [C] Sonnet orchestrator + Haiku workers + Sonnet validator ← ✓ CORRECT
  [D] Use the same model for all agents

ANSWER: C

EXPLANATION:
  The recommended pattern is: Sonnet as orchestrator (coordinates), Haiku workers (parallel execution), Sonnet validator (final check). This is 2-2.5x cheaper than using Opus everywhere with equivalent quality for 90% of tasks. For example, refactoring 100 files: Sonnet analyzes and plans, Haiku does parallel edits, Sonnet validates - saving 80-90% cost.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should an agent's output format section include?

OPTIONS:
  [A] Only code examples
  [B] Structured deliverables like reports with sections, severity levels, and recommendations ← ✓ CORRECT
  [C] Raw text output
  [D] JSON only

ANSWER: B

EXPLANATION:
  An agent's output format should specify structured deliverables. For example, a code reviewer agent outputs: Summary, Critical Issues (Must Fix) with file:line references, Warnings (Should Fix), Suggestions (Nice to Have), and Positive Notes. Clear output format ensures consistent, actionable results across all invocations.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the purpose of the 'disallowedTools' field in agent frontmatter?

OPTIONS:
  [A] To list tools the agent must use
  [B] To block specific tools from being used by the agent ← ✓ CORRECT
  [C] To disable the agent
  [D] To list deprecated tools

ANSWER: B

EXPLANATION:
  The disallowedTools field blocks specific tools from being used by the agent. For example, a code reviewer agent might have `disallowedTools: [WebSearch]` to ensure it focuses on the actual code rather than searching the web. This provides security boundaries and focuses the agent on its core purpose.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-014          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Split Role Sub-Agents' pattern?

OPTIONS:
  [A] Dividing one agent into multiple files
  [B] Multi-perspective analysis using parallel agents with different expert roles ← ✓ CORRECT
  [C] Splitting code review into phases
  [D] Assigning agents to different team members

ANSWER: B

EXPLANATION:
  Split Role Sub-Agents provide multi-perspective analysis in parallel. Process: 1) Activate Plan Mode (thinking enabled by default in Opus 4.5), 2) Ask "What expert roles would analyze this?", 3) Select roles (e.g., Security Expert, Senior Dev, Code Reviewer), 4) Run parallel analysis from each perspective, 5) Consolidate reports into recommendations. Great for comprehensive code and UX reviews.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-015          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should parallel execution of agents be avoided?

OPTIONS:
  [A] When tasks are read-only
  [B] When tasks are destructive (write operations) and dependent on each other ← ✓ CORRECT
  [C] When using haiku model
  [D] When more than 3 agents are involved

ANSWER: B

EXPLANATION:
  Avoid parallel execution for destructive (write) operations that are dependent on each other. The decision matrix: Independent + Non-destructive = Parallel (max efficiency); Independent + Destructive = Sequential with Plan Mode first; Dependent operations = Sequential (order matters). Parallel writes risk conflicts if files share imports/exports.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-016          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does a Debugger agent's methodology typically include?

OPTIONS:
  [A] Only fixing code
  [B] Reproduce, Isolate, Analyze, Hypothesize, Test, Fix, Verify ← ✓ CORRECT
  [C] Just running tests
  [D] Deleting problematic code

ANSWER: B

EXPLANATION:
  A systematic Debugger agent follows: 1) Reproduce - confirm the issue exists, 2) Isolate - narrow down to smallest reproducible case, 3) Analyze - read code, check logs, trace execution, 4) Hypothesize - form theories about cause, 5) Test - verify hypothesis with minimal changes, 6) Fix - implement solution, 7) Verify - confirm fix works without breaking other things. Never guess - always verify.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-017          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is an example of a BAD agent description?

OPTIONS:
  [A] 'Use when designing APIs, reviewing database schemas, or optimizing backend performance'
  [B] 'Backend stuff' ← ✓ CORRECT
  [C] 'Security code reviewer - use PROACTIVELY when reviewing auth code'
  [D] 'Use when encountering errors, test failures, or unexpected behavior'

ANSWER: B

EXPLANATION:
  "Backend stuff" is a bad description - it's too vague to help Claude know when to activate the agent. Good descriptions are specific: "Use when designing APIs, reviewing database schemas, or optimizing backend performance" or "Security code reviewer - use PROACTIVELY when reviewing auth code." Clear activation triggers improve agent utilization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-018          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the invocation reliability difference between CLAUDE.md (eager context) and Skills (lazy invocation)?

OPTIONS:
  [A] Skills are more reliable than CLAUDE.md
  [B] Both have 100% reliability
  [C] CLAUDE.md: 100% reliable (always loaded) vs Skills: 53-79% auto-invoked ← ✓ CORRECT
  [D] CLAUDE.md is deprecated in favor of Skills

ANSWER: C

EXPLANATION:
  CLAUDE.md uses eager context loading - always present in Claude's context, so 100% reliable activation. Skills use lazy invocation - auto-detected and invoked only when Claude recognizes the need, achieving 53-79% auto-invocation rate. Trade-off: CLAUDE.md costs context tokens on every session, Skills save tokens but may miss activations. Use CLAUDE.md for critical behaviors, Skills for optional capabilities.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: ARCHITECTURE INTERNALS
# 15 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-001          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the core architecture pattern of Claude Code?

OPTIONS:
  [A] A DAG orchestrator with task planning
  [B] A simple while(tool_call) loop with no classifier ← ✓ CORRECT
  [C] A RAG pipeline with embeddings
  [D] A multi-agent system with intent router

ANSWER: B

EXPLANATION:
  Claude Code runs a remarkably simple `while(tool_call)` loop. There is NO intent classifier, task router, RAG/embedding pipeline, DAG orchestrator, or planner/executor split. The model itself decides when to call tools, which tools to call, and when it's done. This is the "agentic loop" pattern.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How many core tools does Claude Code have?

OPTIONS:
  [A] 5 tools
  [B] 8 tools ← ✓ CORRECT
  [C] 12 tools
  [D] Unlimited (model-dependent)

ANSWER: B

EXPLANATION:
  Claude Code has exactly 8 core tools: Bash (universal adapter), Read (file contents), Edit (modify files), Write (create/overwrite), Grep (search contents), Glob (find files), Task (sub-agents), and TodoWrite (progress tracking). That's the entire arsenal.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-003          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which tool is described as Claude's 'swiss-army knife' and 'universal adapter'?

OPTIONS:
  [A] Read
  [B] Grep
  [C] Bash ← ✓ CORRECT
  [D] Task

ANSWER: C

EXPLANATION:
  Bash is Claude's swiss-army knife. It can run any CLI tool (git, npm, docker, curl...), execute scripts, chain commands with pipes, and access system state. The model has been trained on massive amounts of shell data, making it highly effective as a universal adapter.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-004          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the approximate context budget for Claude Code with Claude 3.5 Sonnet?

OPTIONS:
  [A] ~32K tokens
  [B] ~100K tokens
  [C] ~200K tokens ← ✓ CORRECT
  [D] ~500K tokens

ANSWER: C

EXPLANATION:
  Claude Code operates within a ~200K token context window. This is shared between: system prompt (~5-15K), CLAUDE.md files (~1-10K), conversation history (variable), tool results (variable), and reserved response buffer (~40-45K). Usable space is approximately 140-150K tokens.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the reported auto-compaction thresholds for Claude Code?

OPTIONS:
  [A] 50-60%
  [B] 75-92% (conflicting reports) ← ✓ CORRECT
  [C] 95-99%
  [D] No auto-compaction exists

ANSWER: B

EXPLANATION:
  Auto-compaction thresholds vary by source: PromptLayer analysis reports 92%, community observations report 75-80%. When triggered, older conversation turns are summarized, tool results condensed, and recent context preserved. Use /compact to manually trigger summarization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-006          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the maximum depth for sub-agents spawned via the Task tool?

OPTIONS:
  [A] Unlimited depth
  [B] Depth = 3
  [C] Depth = 1 (cannot spawn sub-sub-agents) ← ✓ CORRECT
  [D] Depth = 2

ANSWER: C

EXPLANATION:
  Sub-agents have a depth=1 limit. They CANNOT spawn sub-sub-agents. This prevents: recursive explosion (infinite resources), context pollution (accumulated context), debugging nightmares (multi-level chains), and unpredictable costs (nested token usage).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-007          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does a sub-agent receive when spawned by the Task tool?

OPTIONS:
  [A] Full conversation history + all file reads
  [B] Task description only (isolated fresh context) ← ✓ CORRECT
  [C] Last 10 messages of conversation
  [D] System prompt + CLAUDE.md files

ANSWER: B

EXPLANATION:
  Sub-agents have ISOLATED context. They receive only the task description, have their own fresh context window, access the same tools (except Task), and return only a summary text. This isolation keeps the main context clean and prevents context pollution.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-008          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 4 permission layers in Claude Code's security model?

OPTIONS:
  [A] User, Admin, System, Root
  [B] Interactive prompts, Allow/Deny rules, Hooks, Sandbox ← ✓ CORRECT
  [C] Read, Write, Execute, Delete
  [D] Local, Project, Global, Enterprise

ANSWER: B

EXPLANATION:
  Claude Code has 4 layered security: (1) Interactive prompts (allow once/always/deny), (2) Allow/Deny rules in settings.json, (3) Hooks (Pre/Post execution scripts), (4) Sandbox mode (filesystem + network isolation). Each layer adds protection.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What algorithm does the Edit tool use when exact match fails?

OPTIONS:
  [A] Returns error immediately
  [B] Fuzzy match (whitespace normalization, line ending normalization, context expansion) ← ✓ CORRECT
  [C] Regex pattern matching
  [D] Semantic similarity search

ANSWER: B

EXPLANATION:
  When exact match fails, Edit attempts fuzzy matching: (1) Whitespace normalization (trailing spaces, indentation), (2) Line ending normalization (CRLF vs LF), (3) Context expansion (surrounding lines). Only if fuzzy match also fails does it return an error.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-010          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What protocol does MCP (Model Context Protocol) use for communication?

OPTIONS:
  [A] REST API over HTTPS
  [B] GraphQL
  [C] JSON-RPC 2.0 over stdio or HTTP ← ✓ CORRECT
  [D] gRPC with Protocol Buffers

ANSWER: C

EXPLANATION:
  MCP uses JSON-RPC 2.0 over stdio or HTTP transport. MCP tools follow the naming convention `mcp__<server>__<tool>`. Servers start on first use and stay alive during the session. They have the same permission system as native tools.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is Claude Code's design philosophy, as stated by Anthropic?

OPTIONS:
  [A] More scaffolding, less model - build complex orchestration
  [B] Less scaffolding, more model - trust Claude's reasoning ← ✓ CORRECT
  [C] Maximum control - explicit rules for every case
  [D] Hybrid approach - RAG + classifier + model

ANSWER: B

EXPLANATION:
  Claude Code's philosophy is "Less scaffolding, more model" - trust Claude's reasoning instead of building complex orchestration systems. This means: single model decides (no classifier/router), Grep+Glob (no RAG), simple while loop (no DAG), conversation as state (no state machines).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 4 specialized sub-agent types available in Claude Code?

OPTIONS:
  [A] Reader, Writer, Searcher, Executor
  [B] Explore, Plan, general-purpose (3 types) ← ✓ CORRECT
  [C] Junior, Senior, Expert, Architect
  [D] Fast, Balanced, Thorough, Complete

ANSWER: B

EXPLANATION:
  Claude Code offers 3 built-in sub-agent types via the Task tool's subagent_type parameter:
  
  1. **Explore** (Haiku): Codebase exploration with read-only tools. Optimized for file discovery and code search with thoroughness levels (quick/medium/very thorough).
  
  2. **Plan** (Inherit): Architecture planning and research during plan mode. Read-only tools prevent infinite nesting.
  
  3. **general-purpose** (Inherit): Complex multi-step tasks with all tools available (Read, Edit, Write, Bash, Grep, Glob).
  
  **Important**: Bash is a TOOL (command execution utility), not a sub-agent type. Sub-agents can USE the Bash tool, but there is no "Bash" sub-agent type.
  
  Source: Official documentation code.claude.com/docs/en/sub-agents (verified 2026-02-03)

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What tool replaced TodoWrite for task management in Claude Code v2.1.16+?

OPTIONS:
  [A] ProjectManager API
  [B] Kanban tool
  [C] Tasks API (TaskCreate, TaskGet, TaskList, TaskUpdate) ← ✓ CORRECT
  [D] AgendaWrite tool

ANSWER: C

EXPLANATION:
  The Tasks API (v2.1.16+) replaced TodoWrite with 4 tools: TaskCreate (create tasks with descriptions), TaskGet (fetch full task details), TaskList (list all tasks with status), TaskUpdate (update status, dependencies, metadata). Key improvement: task dependencies via blockedBy/blocks fields.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-014          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the API cost overhead of fetching full details for 50 tasks via Tasks API?

OPTIONS:
  [A] 10x overhead (10 API calls)
  [B] 25x overhead (25 API calls)
  [C] 51x overhead (1 TaskList + 50 TaskGet calls required) ← ✓ CORRECT
  [D] 100x overhead (100 API calls)

ANSWER: C

EXPLANATION:
  Tasks API limitation: TaskList returns only summary fields (id, subject, status, owner, blockedBy). To get full details (description, metadata), you need individual TaskGet calls. For 50 tasks: 1 TaskList + 50 TaskGet = 51 API calls. This N+1 pattern is a known limitation compared to TodoWrite which returned everything in one call.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-015          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is TeammateTool and what is its status?

OPTIONS:
  [A] Production-ready multi-agent framework
  [B] Experimental multi-agent coordination (spawnTeam, discoverTeams, requestJoin, approveJoin) - unstable, no official support ← ✓ CORRECT
  [C] Official Anthropic tool for team collaboration
  [D] Deprecated feature replaced by Tasks API

ANSWER: B

EXPLANATION:
  TeammateTool is an experimental multi-agent coordination tool with 4 operations: spawnTeam, discoverTeams, requestJoin, approveJoin. Status: unstable, not officially supported by Anthropic. It allows Claude instances to form teams and coordinate, but the API is subject to change without notice. Not recommended for production use.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: COMMANDS
# 12 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where should custom commands be placed to make them available in Claude Code?

OPTIONS:
  [A] ~/.claude/commands/
  [B] .claude/commands/ ← ✓ CORRECT
  [C] /usr/local/claude/commands/
  [D] .claude/config/commands/

ANSWER: B

EXPLANATION:
  Custom commands are placed in `.claude/commands/` within your project directory.
  
  This allows project-specific commands that can be committed with your codebase.
  The global directory `~/.claude/` is for personal settings, not project commands.
  
  Commands are organized in subdirectories:
  - `.claude/commands/tech/` for development workflows
  - `.claude/commands/product/` for product workflows
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you invoke a custom command named `commit.md` located in `.claude/commands/tech/`?

OPTIONS:
  [A] /commit
  [B] /tech-commit
  [C] /tech:commit ← ✓ CORRECT
  [D] !tech/commit

ANSWER: C

EXPLANATION:
  Custom commands use the format `/folder:filename` (without the .md extension).
  
  So `.claude/commands/tech/commit.md` becomes `/tech:commit`.
  This naming convention allows organizing commands by domain while keeping invocation intuitive.
  
  Examples:
  - `.claude/commands/tech/pr.md` -> `/tech:pr`
  - `.claude/commands/product/scope.md` -> `/product:scope`
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What variable is used in command files to access arguments passed to the command?

OPTIONS:
  [A] $ARGS
  [B] $INPUT
  [C] $ARGUMENTS ← ✓ CORRECT
  [D] $PARAMS

ANSWER: C

EXPLANATION:
  The `$ARGUMENTS` variable contains any text passed after the command invocation.
  
  For example, when you run `/tech:deploy production`, the variable `$ARGUMENTS`
  will contain `production`.
  
  This enables dynamic commands that can adapt based on user input.
  Commands should document how they handle arguments and what happens if none are provided.
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which built-in command shows all available commands including custom ones?

OPTIONS:
  [A] /commands
  [B] /list
  [C] /help ← ✓ CORRECT
  [D] /show

ANSWER: C

EXPLANATION:
  The `/help` command displays all available commands, both built-in and custom.
  
  Built-in commands include:
  - `/clear` - Clear conversation
  - `/compact` - Summarize context
  - `/status` - Show session info
  - `/plan` - Enter Plan Mode
  - `/rewind` - Undo changes
  
  Custom commands from `.claude/commands/` are also listed here.
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What sections should a well-structured command template include according to best practices?

OPTIONS:
  [A] Purpose, Steps, Output
  [B] Purpose, Process, Arguments, Output Format, Examples, Error Handling ← ✓ CORRECT
  [C] Name, Description, Code
  [D] Title, Body, Footer

ANSWER: B

EXPLANATION:
  A complete command template should include:
  
  1. **Purpose** - Brief description of what the command does
  2. **Process** - Step-by-step instructions Claude should follow
  3. **Arguments** - How to handle $ARGUMENTS (if provided/not provided)
  4. **Output Format** - Expected structure of the output
  5. **Examples** - Concrete usage examples
  6. **Error Handling** - How to handle edge cases and failures
  
  This comprehensive structure ensures consistent, reliable command execution.
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-006          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which command enters Plan Mode for safe, read-only exploration?

OPTIONS:
  [A] /safe
  [B] /readonly
  [C] /plan ← ✓ CORRECT
  [D] /explore

ANSWER: C

EXPLANATION:
  The `/plan` command enters Plan Mode, where Claude can analyze and explore
  the codebase without making any changes.
  
  This is ideal for:
  - Understanding unfamiliar codebases
  - Architectural analysis before changes
  - Safe exploration of risky operations
  
  Use `/execute` to exit Plan Mode when ready to make changes.
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-007          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the commit command example, what is the recommended commit message format?

OPTIONS:
  [A] Simple description
  [B] Conventional Commits: type(scope): description ← ✓ CORRECT
  [C] Date - Author - Message
  [D] JIRA-123: Message

ANSWER: B

EXPLANATION:
  The guide recommends Conventional Commits format: `type(scope): description`
  
  Common types:
  - `feat`: New feature
  - `fix`: Bug fix
  - `refactor`: Code restructuring
  - `docs`: Documentation
  - `test`: Test changes
  - `chore`: Maintenance
  
  This provides consistent, parseable commit history useful for changelogs and releases.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-008          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What technique does the Problem Framer command use to find root causes?

OPTIONS:
  [A] SWOT Analysis
  [B] 5 Whys Analysis ← ✓ CORRECT
  [C] Pareto Analysis
  [D] Fishbone Diagram

ANSWER: B

EXPLANATION:
  The Problem Framer command uses the "5 Whys Analysis" technique.
  
  This involves asking "Why?" five times to drill down to the root cause:
  - Why 1: First answer
  - Why 2: Deeper answer
  - Why 3: Even deeper
  - Why 4: Getting to root
  - Why 5: Root cause
  
  The command then reframes the problem as: "How might we [action] for [user] so that [outcome]?"
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-009          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the `/rewind` command do?

OPTIONS:
  [A] Restores a previous git commit
  [B] Undoes Claude's recent changes in the current session ← ✓ CORRECT
  [C] Clears the entire conversation history
  [D] Rolls back the last command execution

ANSWER: B

EXPLANATION:
  The `/rewind` command undoes Claude's recent changes in the current session.
  
  Key points:
  - Works only for uncommitted changes made by Claude
  - Does NOT create git commits
  - Use when Claude made a mistake and you want to try a different approach
  
  For committed changes, use `git revert` instead.
  The keyboard shortcut `Esc×2` (double-tap Escape) also triggers rewind.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-010          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should a PR command's error handling do if the user is NOT on a feature branch?

OPTIONS:
  [A] Automatically create a feature branch
  [B] Proceed anyway with warnings
  [C] WARN: Create a feature branch first ← ✓ CORRECT
  [D] Exit silently

ANSWER: C

EXPLANATION:
  According to the PR command example, if the user is not on a feature branch,
  the command should WARN: "Create a feature branch first".
  
  Similarly, if the working directory is dirty, it should ASK: "Commit changes first?"
  
  Good command design includes clear error handling that:
  - Warns users about prerequisites
  - Suggests corrective actions
  - Prevents accidental mistakes
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-011          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended order of git commands in a PR creation workflow?

OPTIONS:
  [A] push, diff, create PR
  [B] status, branch, log, diff, push if needed, create PR ← ✓ CORRECT
  [C] add, commit, push, create PR
  [D] checkout, status, push, create PR

ANSWER: B

EXPLANATION:
  The recommended PR workflow order is:
  
  1. `git status` - Verify clean working directory
  2. `git branch` - Confirm on feature branch
  3. `git log main..HEAD` - Review all commits
  4. `git diff main...HEAD` - See all changes vs main
  5. `git push -u origin [branch]` - Push if not already pushed
  6. `gh pr create` - Create the PR
  
  This thorough process ensures quality PRs with proper context.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-012          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you reference a file when talking to Claude Code?

OPTIONS:
  [A] #filename
  [B] @filename ← ✓ CORRECT
  [C] !filename
  [D] $filename

ANSWER: B

EXPLANATION:
  The `@filename` syntax references a file in your conversation with Claude.
  
  Quick actions:
  - `@file` - Reference a file
  - `!command` - Run a shell command
  - `Ctrl+C` - Cancel operation
  - `Ctrl+R` - Retry last
  
  This allows you to easily bring specific files into context for Claude to analyze.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: CORE CONCEPTS
# 18 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  At what context percentage should you use /compact?

OPTIONS:
  [A] 0-50%
  [B] 50-70%
  [C] 70-90% ← ✓ CORRECT
  [D] Only at 100%

ANSWER: C

EXPLANATION:
  Use /compact when context reaches 70-90% (the red zone). The context zones are: Green (0-50%) - work freely; Yellow (50-75%) - start being selective; Red (75-90%) - use /compact; Critical (90%+) - must /clear or risk errors. Using /compact at 70% reduces usage by approximately 50% while preserving key context.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is Claude's context window size?

OPTIONS:
  [A] 50,000 tokens
  [B] 100,000 tokens
  [C] 200,000 tokens ← ✓ CORRECT
  [D] 500,000 tokens

ANSWER: C

EXPLANATION:
  Claude has a 200,000 token context window. Think of it like RAM - when it fills up, things slow down or fail. This context includes all messages, files read, command outputs, and tool results. Effective context management is described as "the most important concept in Claude Code."
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the statusline 'Ctx(u): 45%' indicate?

OPTIONS:
  [A] 45% of your budget is remaining
  [B] You've used 45% of your context ← ✓ CORRECT
  [C] 45% of files are loaded
  [D] Claude is 45% confident

ANSWER: B

EXPLANATION:
  The statusline metric 'Ctx(u): 45%' shows you've used 45% of your context window. The full statusline format is: `Claude Code | Ctx(u): 45% | Cost: $0.23 | Session: 1h 23m`. Monitoring this helps you know when to use /compact or /clear before context-related issues occur.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the difference between /compact and /clear?

OPTIONS:
  [A] /compact is faster, /clear is more thorough
  [B] /compact summarizes context (preserves key info), /clear starts completely fresh (loses all context) ← ✓ CORRECT
  [C] /compact clears files, /clear clears conversations
  [D] They do the same thing

ANSWER: B

EXPLANATION:
  /compact summarizes the conversation, preserving key context while reducing usage by approximately 50%. Use it when running low on context. /clear starts completely fresh, losing all context - use it when changing topics or context is severely bloated. Choose based on whether you need to maintain continuity.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which action consumes the MOST context tokens?

OPTIONS:
  [A] Reading a small file (~500 tokens)
  [B] Running a simple command (~1K tokens)
  [C] Reading a large file or multi-file search (~5K+ tokens) ← ✓ CORRECT
  [D] Sending a short message

ANSWER: C

EXPLANATION:
  Reading large files (5K+ tokens) and multi-file searches (3K+ tokens) consume the most context. A small file costs ~500 tokens, running commands ~1K tokens. Long conversations accumulate over time. To optimize, be specific in queries, use symbol references like "read the calculateTotal function" instead of entire files.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-006          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Last 20% Rule' in context management?

OPTIONS:
  [A] Always keep the last 20% of your conversation
  [B] Reserve ~20% of context for multi-file operations, corrections, and summary generation at session end ← ✓ CORRECT
  [C] Delete 20% of context regularly
  [D] Use only 20% of available context

ANSWER: B

EXPLANATION:
  The Last 20% Rule recommends reserving approximately 20% of your context for: multi-file operations at end of session, last-minute corrections, and generating summary/checkpoint documents. This buffer ensures you can complete your work properly even as context fills up.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-007          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'context poisoning' (also called context bleeding)?

OPTIONS:
  [A] When context usage reaches 100%
  [B] When information from one task contaminates another ← ✓ CORRECT
  [C] When Claude forgets your instructions
  [D] When files get corrupted

ANSWER: B

EXPLANATION:
  Context poisoning occurs when information from one task contaminates another. Examples include: style bleeding (blue button style applies to unrelated forms), instruction contamination (conflicting rules cause confusion), and temporal confusion (Claude uses outdated file names). Use explicit task boundaries and clarify priorities to prevent it.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-008          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 7-step interaction loop in Claude Code?

OPTIONS:
  [A] Plan, Code, Test, Deploy, Monitor, Fix, Repeat
  [B] Describe, Analyze, Propose, Review, Decide, Verify, Commit ← ✓ CORRECT
  [C] Read, Write, Edit, Run, Debug, Test, Push
  [D] Ask, Wait, Accept, Run, Check, Fix, Done

ANSWER: B

EXPLANATION:
  The interaction loop is: 1) DESCRIBE - explain what you need, 2) ANALYZE - Claude explores the codebase, 3) PROPOSE - Claude suggests changes (diff), 4) REVIEW - you read and evaluate, 5) DECIDE - Accept/Reject/Modify, 6) VERIFY - run tests, check behavior, 7) COMMIT - save changes (optional). The key insight: you remain in control throughout.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-009          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you exit Plan Mode to start making changes?

OPTIONS:
  [A] /edit
  [B] /execute ← ✓ CORRECT
  [C] /start
  [D] /exit-plan

ANSWER: B

EXPLANATION:
  Use /execute to exit Plan Mode and begin implementing changes. While in Plan Mode, Claude can only read and analyze - no modifications are allowed. You can also respond to Claude's prompt "Ready to implement this plan?" to transition. This staged approach ensures you understand the plan before execution.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-010          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is OpusPlan mode?

OPTIONS:
  [A] A premium subscription tier
  [B] Using Opus for planning (superior reasoning) and Sonnet for implementation (cost-efficient) ← ✓ CORRECT
  [C] A debugging mode
  [D] A way to plan without Claude

ANSWER: B

EXPLANATION:
  OpusPlan uses Opus for planning (with superior reasoning capabilities) and automatically switches to Sonnet for implementation (more cost-efficient). Enable with `/model opusplan`. This provides Opus-quality planning while preserving tokens through Sonnet-speed execution. Particularly valuable for Pro subscribers with limited Opus tokens.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are symptoms of context depletion?

OPTIONS:
  [A] Claude types slower
  [B] Shorter responses, forgetting CLAUDE.md instructions, inconsistencies with earlier conversation ← ✓ CORRECT
  [C] Error messages appear
  [D] Cost increases dramatically

ANSWER: B

EXPLANATION:
  Context depletion symptoms include: shorter responses than usual (warning), forgetting CLAUDE.md instructions (serious), inconsistencies with earlier conversation (critical), errors on code already discussed (critical), and "I can't access that file" for files already read (critical). When critical symptoms appear, start a new session immediately.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-012          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What can /rewind do?

OPTIONS:
  [A] Undo git commits
  [B] Revert Claude's file changes within the current session ← ✓ CORRECT
  [C] Go back in conversation history
  [D] Restore deleted files from disk

ANSWER: B

EXPLANATION:
  /rewind reverts file changes made by Claude. It works across multiple files but only on Claude's changes (not manual edits), only within the current session, and does NOT automatically revert git commits. For risky operations, create a git checkpoint first: "Let's commit what we have before trying this experimental approach."
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-013          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does Claude NOT have access to regarding your project?

OPTIONS:
  [A] File structure and code content
  [B] Git state and branches
  [C] Runtime state, external services, and hidden files ← ✓ CORRECT
  [D] Project rules in CLAUDE.md

ANSWER: C

EXPLANATION:
  Claude knows: file structure, code content, git state, and project rules (CLAUDE.md). Claude does NOT know: runtime state (can't see running processes), external services (can't access databases directly), your intent (needs clear instructions), and hidden files (respects .gitignore by default). Understanding this mental model helps you communicate effectively.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-014          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the purpose of the 'Sanity Check Technique'?

OPTIONS:
  [A] To verify code compiles correctly
  [B] To verify Claude has loaded your CLAUDE.md configuration correctly ← ✓ CORRECT
  [C] To check for memory leaks
  [D] To validate test coverage

ANSWER: B

EXPLANATION:
  The Sanity Check Technique verifies Claude loaded your configuration. Add identifiable info to CLAUDE.md (like your name, project name, tech stack), then ask Claude "What is my name? What project am I working on?" Correct answers confirm configuration is loaded. For advanced checking, add multiple checkpoints throughout long CLAUDE.md files.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-015          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you use XML-structured prompts?

OPTIONS:
  [A] For all prompts regardless of complexity
  [B] For multi-step features, bug investigations with context, and code reviews with specific criteria ← ✓ CORRECT
  [C] Only for simple one-liner requests
  [D] Only when working with APIs

ANSWER: B

EXPLANATION:
  Use XML-structured prompts when requests have 3+ distinct aspects (instruction + context + constraints), when ambiguity causes misunderstanding, when creating reusable templates, or for complex hierarchy. Don't use them for simple one-liner requests or quick typo fixes - the overhead outweighs the benefit. Tags like <instruction>, <context>, <constraints> help Claude understand different aspects.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-016          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a 'Session Handoff Pattern' used for?

OPTIONS:
  [A] Transferring sessions between team members
  [B] Documenting state, decisions, and next steps to maintain continuity between sessions ← ✓ CORRECT
  [C] Backing up your code
  [D] Exporting conversation history

ANSWER: B

EXPLANATION:
  The Session Handoff Pattern creates a document to bridge gaps between sessions. It includes: what was accomplished, current state, decisions made, next steps, and context for the next session. Create handoffs at end of work day, before context limit, when switching focus areas, or during interruptions. Store in `claudedocs/handoffs/handoff-YYYY-MM-DD.md`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-017          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the typical cost of a 1-hour Claude Code session?

OPTIONS:
  [A] $0.01 - $0.05
  [B] $0.10 - $0.50 ← ✓ CORRECT
  [C] $1.00 - $5.00
  [D] $10.00 - $20.00

ANSWER: B

EXPLANATION:
  A typical 1-hour session costs $0.10 - $0.50 depending on usage patterns. The guide provides cost budgets: quick task (5-10 min) $0.05-$0.10, feature work (1-2 hours) $0.20-$0.50, deep refactor (half day) $1.00-$2.00. Spending $0.50 to save 30 minutes provides 60x ROI if your time is worth $30/hour - don't over-optimize!
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-018          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is Auto Plan Mode and how do you enable it?

OPTIONS:
  [A] Automatic planning that's always on by default
  [B] A configuration that forces Claude to present a plan and wait for approval before any tool execution ← ✓ CORRECT
  [C] A mode that automatically generates project plans
  [D] A premium feature for enterprise users

ANSWER: B

EXPLANATION:
  Auto Plan Mode makes Claude present a plan and wait for explicit user approval before executing ANY tool. Configure via `~/.claude/auto-plan-mode.txt` and launch with `claude --append-system-prompt "$(cat ~/.claude/auto-plan-mode.txt)"`. Results in 76% fewer tokens with better results because plans are validated before execution.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: HOOKS
# 16 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What exit code should a hook return to BLOCK an operation?

OPTIONS:
  [A] 0
  [B] 1
  [C] 2 ← ✓ CORRECT
  [D] 255

ANSWER: C

EXPLANATION:
  Hook exit codes have specific meanings:
  
  - **Exit code 0**: Success - Allow the operation to proceed
  - **Exit code 2**: Block - Prevent the operation from executing
  - **Other codes**: Error - Log the error and continue
  
  This is critical for security hooks that need to prevent dangerous commands.
  For example, a hook that detects `rm -rf /` should `exit 2` to block execution.
  

OFFICIAL DOC: https://code.claude.com/docs/en/hooks

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which hook event fires BEFORE a tool is executed?

OPTIONS:
  [A] BeforeToolUse
  [B] PreToolUse ← ✓ CORRECT
  [C] ToolStart
  [D] OnToolCall

ANSWER: B

EXPLANATION:
  The `PreToolUse` event fires before any tool runs.
  
  Common event types:
  - **PreToolUse**: Before tool execution (ideal for security validation)
  - **PostToolUse**: After tool execution (for formatting, logging)
  - **UserPromptSubmit**: When user sends a message (context enrichment)
  - **Notification**: When Claude sends a notification
  - **SessionStart/SessionEnd**: Session lifecycle events
  - **Stop**: When user interrupts
  

OFFICIAL DOC: https://code.claude.com/docs/en/hooks

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do hooks receive input data from Claude Code?

OPTIONS:
  [A] As command-line arguments
  [B] As JSON on stdin ← ✓ CORRECT
  [C] As environment variables
  [D] From a temporary file

ANSWER: B

EXPLANATION:
  Hooks receive JSON data on stdin with information about the event.
  
  Example input structure:
  ```json
  {
    "tool_name": "Bash",
    "tool_input": {
      "command": "git status"
    },
    "session_id": "abc123",
    "cwd": "/project"
  }
  ```
  
  Hooks typically parse this with: `INPUT=$(cat)` followed by `jq` for JSON extraction.
  

OFFICIAL DOC: https://code.claude.com/docs/en/hooks

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-004          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the hook registration (settings.json), what does the `matcher` field specify?

OPTIONS:
  [A] File extensions to watch
  [B] Regex pattern for which tools trigger the hook ← ✓ CORRECT
  [C] User permission levels
  [D] Output format requirements

ANSWER: B

EXPLANATION:
  The `matcher` field is a regex pattern that determines which tools trigger the hook.
  
  Example configuration:
  ```json
  {
    "matcher": "Bash|Edit|Write",
    "hooks": [{"type": "command", "command": "./hooks/security-check.sh"}]
  }
  ```
  
  This hook would trigger for Bash, Edit, or Write tools.
  You can match specific tools or use `.*` to match all tools.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-005          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the best use case for the `UserPromptSubmit` hook event?

OPTIONS:
  [A] Blocking dangerous commands
  [B] Auto-formatting code
  [C] Adding context like git status to every prompt ← ✓ CORRECT
  [D] Playing notification sounds

ANSWER: C

EXPLANATION:
  The `UserPromptSubmit` event is ideal for context enrichment.
  
  Use cases:
  - **UserPromptSubmit**: Add context (git status, current branch, staged files)
  - **PreToolUse**: Security validation (block dangerous commands)
  - **PostToolUse**: Formatting, logging, quality checks
  - **Notification**: Sound alerts, desktop notifications
  
  The context enricher example adds git branch, last commit, and staged/unstaged info.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-006          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What exit code allows an operation to proceed?

OPTIONS:
  [A] 1
  [B] 0 ← ✓ CORRECT
  [C] 2
  [D] -1

ANSWER: B

EXPLANATION:
  Exit code 0 means success and allows the operation to proceed.
  
  The exit code system:
  - **0**: Success - Allow operation
  - **2**: Block - Prevent operation
  - **Other**: Error - Log and continue
  
  Always end your hooks with `exit 0` if you want to allow the operation,
  or `exit 2` to block it.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-007          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which commands should a security hook typically block?

OPTIONS:
  [A] git status, npm test
  [B] rm -rf /, sudo rm, git push --force origin main ← ✓ CORRECT
  [C] cd, ls, pwd
  [D] npm install, pip install

ANSWER: B

EXPLANATION:
  Security hooks should block dangerous operations like:
  
  - `rm -rf /` or `rm -rf ~` - Filesystem destruction
  - `sudo rm` - Privileged deletion
  - `git push --force origin main` - Force push to protected branches
  - `npm publish` - Accidental package publishing
  - `> /dev/sda` or `dd if=` - Direct disk operations
  
  Safe commands like `git status`, `npm test`, `ls` should be allowed.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-008          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What JSON structure should a hook return to send a message back to Claude?

OPTIONS:
  [A] {"message": "text"}
  [B] {"systemMessage": "text", "hookSpecificOutput": {...}} ← ✓ CORRECT
  [C] {"response": "text"}
  [D] {"output": "text"}

ANSWER: B

EXPLANATION:
  Hooks return JSON on stdout with specific fields:
  
  ```json
  {
    "systemMessage": "Message shown to Claude",
    "hookSpecificOutput": {
      "additionalContext": "Extra information"
    }
  }
  ```
  
  - `systemMessage`: Displayed to Claude as context
  - `hookSpecificOutput`: Additional structured data
  
  This allows hooks to provide context that Claude can use in its responses.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended approach for tasks that need 'understanding' vs pattern-based tasks?

OPTIONS:
  [A] Both should use bash scripts
  [B] Both should use AI agents
  [C] Pattern-based use bash scripts; understanding-needed use AI agents ← ✓ CORRECT
  [D] Pattern-based use AI agents; understanding-needed use bash scripts

ANSWER: C

EXPLANATION:
  The guide recommends choosing the right tool:
  
  **Use Bash scripts when:**
  - Tasks are deterministic (create branch, push)
  - Pattern-based (check for secrets with regex)
  - Fast, predictable, no token cost
  
  **Use AI Agents when:**
  - Interpretation is needed (code review quality)
  - Context-dependent decisions
  - Understanding and judgment required
  
  Rule: "If you can write a regex for it, use a bash script."
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which hook event fires AFTER a tool has finished executing?

OPTIONS:
  [A] AfterToolUse
  [B] PostToolUse ← ✓ CORRECT
  [C] ToolComplete
  [D] OnToolDone

ANSWER: B

EXPLANATION:
  The `PostToolUse` event fires after any tool completes execution.
  
  Common use cases for PostToolUse:
  - Auto-formatting code after edits
  - Running linters after file changes
  - Logging tool usage for auditing
  - Triggering tests after code changes
  
  The Auto-Formatter template uses PostToolUse to run Prettier after Edit/Write operations.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-011          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you test a security hook before deploying it?

OPTIONS:
  [A] Run Claude Code and hope it works
  [B] Pipe test JSON to the hook script and check the exit code ← ✓ CORRECT
  [C] Deploy to production and monitor
  [D] Security hooks cannot be tested

ANSWER: B

EXPLANATION:
  Test hooks by piping JSON input and checking the exit code:
  
  ```bash
  # Test with a blocked command
  echo '{"tool_name":"Bash","tool_input":{"command":"rm -rf /"}}' | ./hooks/security-blocker.sh
  echo "Exit code: $?"  # Should be 2
  
  # Test with a safe command
  echo '{"tool_name":"Bash","tool_input":{"command":"git status"}}' | ./hooks/security-blocker.sh
  echo "Exit code: $?"  # Should be 0
  ```
  
  This ensures your hook correctly blocks dangerous commands before deployment.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In Windows, how should hooks be invoked to avoid execution policy restrictions?

OPTIONS:
  [A] Run as Administrator
  [B] Use powershell -ExecutionPolicy Bypass -File script.ps1 ← ✓ CORRECT
  [C] Disable all security settings
  [D] Convert to batch files only

ANSWER: B

EXPLANATION:
  Windows hooks should use the full PowerShell invocation:
  
  ```json
  {
    "type": "command",
    "command": "powershell -ExecutionPolicy Bypass -File .claude/hooks/security-check.ps1"
  }
  ```
  
  This bypasses the default execution policy that might block script execution.
  Batch files (.cmd) can also be used as an alternative for simpler hooks.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-013          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the activity logger hook example use to store logs?

OPTIONS:
  [A] SQLite database
  [B] Plain text files
  [C] JSONL (JSON Lines) files ← ✓ CORRECT
  [D] CSV files

ANSWER: C

EXPLANATION:
  The activity logger hook stores logs in JSONL format (JSON Lines).
  
  Key features:
  - Logs to `~/.claude/logs/activity-YYYY-MM-DD.jsonl`
  - Each entry contains timestamp, tool name, and session ID
  - Auto-cleanup of logs older than 7 days
  - Uses `jq` for JSON construction
  
  JSONL is ideal for log files as each line is a valid JSON object,
  making it easy to append and parse.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the default timeout for hooks in the configuration?

OPTIONS:
  [A] 1000ms (1 second)
  [B] 5000ms (5 seconds) ← ✓ CORRECT
  [C] 30000ms (30 seconds)
  [D] No timeout by default

ANSWER: B

EXPLANATION:
  The example hook configuration shows a timeout of 5000ms (5 seconds).
  
  ```json
  {
    "type": "command",
    "command": ".claude/hooks/security-check.sh",
    "timeout": 5000
  }
  ```
  
  This prevents hooks from blocking Claude Code indefinitely.
  For longer operations like formatting, you might increase this to 10000ms.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-015          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What configuration parameter makes a hook run asynchronously (v2.1.0+)?

OPTIONS:
  [A] background: true
  [B] async: true ← ✓ CORRECT
  [C] nonblocking: true
  [D] mode: async

ANSWER: B

EXPLANATION:
  Since Claude Code v2.1.0, hooks support `async: true` in their configuration. This makes the hook fire without blocking Claude's execution. Useful for logging, notifications, or analytics hooks where you don't need to wait for the result before continuing.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-016          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 limitations of async hooks compared to sync hooks?

OPTIONS:
  [A] Can't access stdin, can't write files, can't read environment variables
  [B] No exit code feedback (can't block), no additionalContext returned, no blocking capability ← ✓ CORRECT
  [C] Can't use network, can't spawn processes, can't read files
  [D] Limited to 1s timeout, no stderr capture, no argument passing

ANSWER: B

EXPLANATION:
  Async hooks trade control for speed:
  
  1. **No exit code feedback** - Can't block Claude based on success/failure
  2. **No additionalContext** - Can't inject context back into the conversation
  3. **No blocking capability** - Fire-and-forget only
  
  Use async for non-critical operations (logging, telemetry). Use sync for security gates, formatting, and validation.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: LEARNING WITH AI
# 17 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the three developer patterns when using AI, according to the Learning with AI guide?

OPTIONS:
  [A] Beginner, Intermediate, Expert
  [B] Dependent, Avoidant, Augmented ← ✓ CORRECT
  [C] Passive, Active, Proactive
  [D] Consumer, Producer, Creator

ANSWER: B

EXPLANATION:
  The three patterns are: Dependent (copy-paste without understanding, can't debug AI code), Avoidant (refuses AI on principle, slower than peers), and Augmented (uses AI critically, understands everything). The goal is to become Augmented - using AI for leverage while maintaining deep understanding.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does UVAL stand for in the AI learning protocol?

OPTIONS:
  [A] Use, Validate, Apply, Learn
  [B] Understand, Verify, Apply, Learn ← ✓ CORRECT
  [C] Understand, Validate, Analyze, Learn
  [D] Use, Verify, Analyze, Log

ANSWER: B

EXPLANATION:
  UVAL stands for: Understand First (the 15-minute rule), Verify (ensure you actually learned), Apply (transform knowledge into skill through modification), Learn (capture insights for long-term retention). This protocol ensures you're learning, not just copying.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-003          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the Quick Self-Check, if you score 0-2 'yes' answers, what does this indicate?

OPTIONS:
  [A] You're an augmented developer
  [B] You're on track with room for optimization
  [C] You're at dependency risk - outsourcing thinking ← ✓ CORRECT
  [D] You're an AI avoidant

ANSWER: C

EXPLANATION:
  A score of 0-2 yes answers indicates dependency risk - you're outsourcing your thinking to AI. The 5 questions test: can you explain AI-generated code, have you debugged without AI, do you know WHY solutions work, could you write the code yourself, do you know AI's limitations. Low scores mean you should read the "Breaking Dependency" section.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-004          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the '15-Minute Rule' in the UVAL protocol's 'Understand First' step?

OPTIONS:
  [A] Limit AI usage to 15 minutes per day
  [B] A 4-step protocol: State problem, Brainstorm approaches, Identify gaps, THEN ask AI ← ✓ CORRECT
  [C] Wait 15 minutes after getting AI response before using it
  [D] Spend 15 minutes explaining AI code to a colleague

ANSWER: B

EXPLANATION:
  The 15-minute rule is a specific protocol: (1) State the problem in ONE sentence (2 min), (2) Brainstorm 3 possible approaches (5 min), (3) Identify your knowledge gaps (3 min), (4) THEN ask AI with a much better question (5 min). This forces you to think before asking, resulting in better questions and faster learning.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-005          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Explain It Back' technique in the UVAL protocol's Verify step?

OPTIONS:
  [A] Ask AI to explain its own code
  [B] Write documentation for the code
  [C] If you can't explain the code to a colleague, you haven't learned it ← ✓ CORRECT
  [D] Record yourself explaining and review later

ANSWER: C

EXPLANATION:
  The rule is simple: if you can't explain the code to a colleague, you don't understand it. This is the verification step - you must be able to articulate WHY the solution works, not just THAT it works. The guide recommends using a /explain-back slash command that asks YOU to explain AI-generated code.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-006          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the 30-Day Progression Plan, what is the AI usage ratio for Week 1?

OPTIONS:
  [A] 0-20% AI usage ← ✓ CORRECT
  [B] 40-50% AI usage
  [C] 60-70% AI usage
  [D] 70-80% AI usage

ANSWER: A

EXPLANATION:
  Week 1 focuses on foundations with 0-20% AI usage: Days 1-2 build feature WITHOUT AI (0%), Days 4-5 refactor with AI review only (20%), Day 6 debug without AI (0%). The goal is to build (or rebuild) core skills without heavy AI reliance. Success criteria: can explain every line you wrote.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-007          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What AI usage ratio does the 30-Day Plan recommend for Week 4 (Augmented stage)?

OPTIONS:
  [A] 30-40%
  [B] 50-60%
  [C] 70% ← ✓ CORRECT
  [D] 90-100%

ANSWER: C

EXPLANATION:
  Week 4 (Augmented stage) recommends 70% AI usage with the UVAL protocol. The progression is: Week 1 (0-20%), Week 2 (30-40%), Week 3 (50-60%), Week 4 (70%). Success criteria for Week 4: you're fast AND you understand everything. The cap at 70% ensures you maintain skills.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-008          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  According to the guide, what is the metaphor for AI in development?

OPTIONS:
  [A] AI is your co-pilot
  [B] AI is your GPS ← ✓ CORRECT
  [C] AI is your assistant
  [D] AI is your teacher

ANSWER: B

EXPLANATION:
  AI is compared to GPS: great for getting somewhere fast, dangerous if you lose the ability to navigate without it, truly useful when you understand the map AND use the GPS. A developer who only copy-pastes AI output is like a driver who can't read a map - fine until the GPS fails or someone asks for directions.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-009          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a 'Red Flag' sign of AI dependency according to the checklist?

OPTIONS:
  [A] Using AI for complex algorithms
  [B] Can't start coding without AI ← ✓ CORRECT
  [C] Using AI for code reviews
  [D] Asking AI to explain concepts

ANSWER: B

EXPLANATION:
  "Can't start without AI" is a red flag indicating you've outsourced problem decomposition. Other red flags: don't understand AI's code, can't debug AI errors, anxiety without AI, rejected in interviews, always ask "how" never "why", every solution looks the same. Immediate action: code 30 min daily without AI.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-010          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Apply' step's core principle in the UVAL protocol?

OPTIONS:
  [A] Apply the code directly to production
  [B] Transform knowledge into skill through MODIFICATION, not copying ← ✓ CORRECT
  [C] Apply code reviews to all AI-generated code
  [D] Apply unit tests to verify correctness

ANSWER: B

EXPLANATION:
  The Apply step requires modification, not copy-paste. You must change at least one element (variable name, structure, edge case handling). Why? Modification forces understanding. Copying is passive; modifying requires you to engage with the code and understand how it works.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What CLAUDE.md configuration enables 'Learning Mode' with Claude Code?

OPTIONS:
  [A] ## Learning Mode - Ask me questions before generating code ← ✓ CORRECT
  [B] ## Strict Mode - Never generate code directly
  [C] ## Teaching Mode - Always explain before showing
  [D] ## Quiz Mode - Test before implementing

ANSWER: A

EXPLANATION:
  Learning Mode in CLAUDE.md prompts Claude to ask questions before generating: "What approaches have I considered?", "What specifically am I stuck on?", "What do I expect the solution to look like?". This implements the UVAL protocol's Understand step directly in your workflow.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What hook event is recommended for capturing daily learning?

OPTIONS:
  [A] PreToolUse - before each command
  [B] PostToolUse - after each edit
  [C] Stop - when session ends ← ✓ CORRECT
  [D] Notification - on alerts

ANSWER: C

EXPLANATION:
  The learning-capture.sh hook uses the Stop event (session end) to prompt: "What's ONE thing you learned today?" This logs to ~/claude-learnings.md automatically. It's lightweight (asks one question) so you'll actually use it, unlike verbose learning journals.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Dependent' pattern's main risk according to the guide?

OPTIONS:
  [A] Slower than peers
  [B] Unemployable ← ✓ CORRECT
  [C] Left behind
  [D] Overworked

ANSWER: B

EXPLANATION:
  The Dependent pattern's risk is becoming unemployable. Signs: copy-paste without understanding, can't debug AI code, anxiety without AI. In interviews: can't whiteboard basics, struggles with "why this approach?", asks to look up fundamentals. You ship code you can't explain - when it breaks, you're stuck.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-014          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the Weekly Self-Audit question that detects dependency?

OPTIONS:
  [A] How many lines of code did I write?
  [B] Am I faster than last month? Am I smarter? ← ✓ CORRECT
  [C] How much did I use AI this week?
  [D] Did I meet all my deadlines?

ANSWER: B

EXPLANATION:
  The key question is: "Am I faster than last month? Am I smarter?" If you're faster but NOT smarter, you're building dependency. Other weekly questions: What did I learn that I didn't know before? Could I have done this without AI? Did I understand everything I shipped?
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-015          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended approach for 'Avoidant' developers (Pattern 2)?

OPTIONS:
  [A] Continue avoiding AI to maintain purity
  [B] Start with AI review of YOUR code, not AI-generated code ← ✓ CORRECT
  [C] Immediately switch to 100% AI usage
  [D] Wait until AI tools are more mature

ANSWER: B

EXPLANATION:
  For Avoidant developers, the guide recommends gradual adoption: start with AI reviewing YOUR code (you stay in control), then move to AI explaining concepts you implement, then AI-assisted work. This respects your instinct for understanding while gaining AI benefits. Pure avoidance means being slower without being smarter.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-016          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 failure modes identified in Addy Osmani's '80% Problem' of agentic coding?

OPTIONS:
  [A] Context loss, token overflow, hallucination
  [B] Overengineering, assumption propagation, sycophantic agreement ← ✓ CORRECT
  [C] Slow responses, wrong language, missed tests
  [D] Memory leaks, race conditions, deadlocks

ANSWER: B

EXPLANATION:
  Addy Osmani's "80% Problem" identifies 3 failure modes:
  
  1. **Overengineering** - AI adds unnecessary complexity (abstraction layers, premature optimization)
  2. **Assumption propagation** - One wrong assumption cascades through the codebase
  3. **Sycophantic agreement** - AI agrees with bad ideas instead of pushing back
  
  The 80% refers to AI getting you 80% of the way, with the last 20% requiring deep human understanding.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 11-017          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 symptoms of vibe coding 'context overload'?

OPTIONS:
  [A] Memory leaks, slow startup, API rate limits
  [B] Big-bang context dumps, 5K+ line prompts, performance degradation ← ✓ CORRECT
  [C] Lost files, broken imports, missing tests
  [D] Excessive commits, merge conflicts, branch proliferation

ANSWER: B

EXPLANATION:
  Context overload symptoms in vibe coding:
  
  1. **Big-bang context dumps** - Pasting entire codebases into prompts
  2. **5K+ line prompts** - Exceeding effective context window usage
  3. **Performance degradation** - Claude's quality drops as context grows
  
  The fix: progressive disclosure (feed context incrementally), use CLAUDE.md for persistent context, and start fresh sessions between phases.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: MCP SERVERS
# 20 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does MCP stand for in the context of Claude Code?

OPTIONS:
  [A] Model Compute Protocol
  [B] Model Context Protocol ← ✓ CORRECT
  [C] Multi-Channel Processing
  [D] Module Configuration Protocol

ANSWER: B

EXPLANATION:
  MCP stands for Model Context Protocol.
  
  It is a standard for connecting AI models to external tools and data sources.
  MCP enables Claude Code to extend beyond built-in tools by connecting to:
  - Semantic code analysis (Serena)
  - Documentation lookup (Context7)
  - Database queries (Postgres)
  - Browser automation (Playwright)
  

OFFICIAL DOC: https://code.claude.com/docs/en/mcp-servers

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-002          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server should you use to find all usages of a function across your codebase?

OPTIONS:
  [A] Context7
  [B] Sequential Thinking
  [C] Serena ← ✓ CORRECT
  [D] Postgres

ANSWER: C

EXPLANATION:
  Serena provides semantic code analysis with tools like `find_referencing_symbols`.
  
  Serena tools include:
  - `find_symbol` - Find functions, classes, methods by name
  - `get_symbols_overview` - Get file structure overview
  - `find_referencing_symbols` - Find all usages of a symbol
  - `search_for_pattern` - Regex search across codebase
  
  Use Serena for deep code understanding and symbol-level analysis.
  

OFFICIAL DOC: https://code.claude.com/docs/en/mcp-servers

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server is best for looking up official library documentation?

OPTIONS:
  [A] Serena
  [B] Context7 ← ✓ CORRECT
  [C] Sequential Thinking
  [D] mgrep

ANSWER: B

EXPLANATION:
  Context7 is designed for accessing official library documentation.
  
  Use Context7 when:
  - Learning new libraries
  - Finding correct API usage
  - Checking official patterns
  
  For example, "How does React useEffect work?" should use Context7
  to get the official documentation rather than generic knowledge.
  

OFFICIAL DOC: https://code.claude.com/docs/en/mcp-servers

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-004          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server provides persistent memory across sessions?

OPTIONS:
  [A] Context7
  [B] Postgres
  [C] Serena ← ✓ CORRECT
  [D] Sequential Thinking

ANSWER: C

EXPLANATION:
  Serena provides session memory that persists across conversations.
  
  Serena memory tools:
  - `write_memory` - Save context for future sessions
  - `read_memory` - Retrieve saved context
  - `list_memories` - List all stored memories
  
  Memory is stored in `.serena/memories/` and survives between Claude Code sessions.
  This is crucial for maintaining context on long-running projects.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-005          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where is the global MCP configuration file located?

OPTIONS:
  [A] ~/.mcp/config.json
  [B] ~/.claude/mcp.json ← ✓ CORRECT
  [C] /etc/claude/mcp.json
  [D] ~/.config/claude/mcp.json

ANSWER: B

EXPLANATION:
  The global MCP configuration is at `~/.claude/mcp.json`.
  
  Configuration locations:
  - `~/.claude/mcp.json` - Global (applies to all projects)
  - `/project/.claude/mcp.json` - Project-specific (overrides global)
  
  The configuration specifies which servers to run and their settings.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-006          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended MCP server for complex debugging scenarios?

OPTIONS:
  [A] Context7
  [B] Serena
  [C] Sequential Thinking ← ✓ CORRECT
  [D] Postgres

ANSWER: C

EXPLANATION:
  Sequential Thinking is designed for multi-step analysis with explicit reasoning.
  
  Use Sequential Thinking for:
  - Complex debugging scenarios
  - Architectural analysis
  - System design decisions
  
  The `sequentialthinking` tool provides step-by-step reasoning that is
  ideal for problems requiring systematic investigation.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-007          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How can MCP servers work together effectively?

OPTIONS:
  [A] They cannot - only one server at a time
  [B] Context7 for patterns -> Serena for code -> Sequential for analysis -> Playwright for testing ← ✓ CORRECT
  [C] All servers must be configured identically
  [D] Servers must be chained in alphabetical order

ANSWER: B

EXPLANATION:
  MCP servers can be combined for powerful workflows:
  
  1. **Context7** - Get official pattern for auth
  2. **Serena** - Find existing auth code in codebase
  3. **Sequential** - Analyze how to integrate
  4. **Playwright** - Test the implementation
  
  This combination leverages each server's strengths for comprehensive development.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-008          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What variable can you use in mcp.json to reference the current project path?

OPTIONS:
  [A] ${projectPath}
  [B] ${workspaceFolder} ← ✓ CORRECT
  [C] ${cwd}
  [D] ${PROJECT_DIR}

ANSWER: B

EXPLANATION:
  The `${workspaceFolder}` variable expands to the current project path.
  
  Variable substitution in mcp.json:
  - `${workspaceFolder}` - Current project path
  - `${env:VAR_NAME}` - Environment variable
  
  Example:
  ```json
  "env": {
    "PROJECT_PATH": "${workspaceFolder}"
  }
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the key advantage of Serena over Claude Code's built-in tools?

OPTIONS:
  [A] It's faster
  [B] It provides indexation that Claude Code lacks ← ✓ CORRECT
  [C] It uses less memory
  [D] It works offline

ANSWER: B

EXPLANATION:
  Serena fills a critical gap: Claude Code has no built-in indexation (unlike Cursor).
  
  Serena provides:
  - **Indexation**: Pre-indexes your codebase for efficient symbol lookup
  - **Project Memory**: Stores context between sessions
  - **Onboarding**: Auto-analyzes project structure on first run
  
  For large codebases (>10k lines), Serena's indexation dramatically improves performance.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-010          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What distinguishes a Plugin from an MCP Server in Claude Code?

OPTIONS:
  [A] Plugins are faster
  [B] Plugins bundle Claude-specific workflows; MCP servers add external tool capabilities ← ✓ CORRECT
  [C] They are identical
  [D] MCP servers are for beginners, plugins for experts

ANSWER: B

EXPLANATION:
  The rule of thumb:
  - **Plugin** = "How Claude thinks" (new workflows, specialized agents)
  - **MCP Server** = "What Claude can do" (new tools, external systems)
  
  Plugins bundle agents, skills, and configuration into installable modules.
  MCP servers add external capabilities like database access or browser automation.
  
  Installation differs too:
  - Plugins: `claude plugin install`
  - MCP: Add to `settings.json` MCP config
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-011          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server is used for browser automation and E2E testing?

OPTIONS:
  [A] Serena
  [B] Context7
  [C] Playwright ← ✓ CORRECT
  [D] Sequential Thinking

ANSWER: C

EXPLANATION:
  Playwright MCP provides browser automation capabilities.
  
  Playwright tools include:
  - `navigate` - Go to URL
  - `click` - Click element
  - `fill` - Fill form field
  - `screenshot` - Capture screenshot
  
  Use Playwright for:
  - E2E testing
  - Visual validation
  - Browser debugging
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you add an MCP server with environment variables via CLI?

OPTIONS:
  [A] claude mcp add --env API_KEY=key server
  [B] claude mcp add -e API_KEY=key my-server -- npx @org/server ← ✓ CORRECT
  [C] claude mcp install server --api-key key
  [D] claude add mcp server -k key

ANSWER: B

EXPLANATION:
  Use the `-e` flag to pass environment variables:
  
  ```bash
  claude mcp add -e API_KEY=your-key my-server -- npx @org/server
  ```
  
  For multiple environment variables:
  ```bash
  claude mcp add -e DATABASE_URL=postgres://... -e DEBUG=true postgres -- npx @prisma/postgres
  ```
  
  This is quicker than manually editing mcp.json.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-013          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is grepai's key differentiator compared to Serena?

OPTIONS:
  [A] It's faster
  [B] It provides semantic search by intent plus call graph analysis ← ✓ CORRECT
  [C] It supports more languages
  [D] It has better documentation

ANSWER: B

EXPLANATION:
  grepai excels at intent-based search using natural language, plus offers
  call graph analysis to trace function dependencies:
  
  ```bash
  # Semantic search (finds code by meaning, not exact text)
  grepai search "user authentication flow"
  
  # Who calls this function?
  grepai trace callers "createSession"
  ```
  
  While Serena focuses on symbol-level analysis, grepai finds code by
  describing what it does and traces caller/callee relationships.
  
  Use grepai for exploring unfamiliar codebases or understanding dependencies.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What command lists all installed plugins in Claude Code?

OPTIONS:
  [A] claude plugins list
  [B] claude plugin ← ✓ CORRECT
  [C] /plugins
  [D] claude list plugins

ANSWER: B

EXPLANATION:
  Running `claude plugin` (without subcommand) lists all installed plugins with status.
  
  Plugin commands:
  - `claude plugin` - List installed plugins
  - `claude plugin install <name>` - Install plugin
  - `claude plugin enable <name>` - Enable plugin
  - `claude plugin disable <name>` - Disable plugin
  - `claude plugin uninstall <name>` - Remove plugin
  - `claude plugin validate <path>` - Validate plugin manifest
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-015          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the main advantage of using Figma MCP over screenshots?

OPTIONS:
  [A] Higher image quality
  [B] 3-10x fewer tokens: structured data vs. image analysis ← ✓ CORRECT
  [C] Faster download speed
  [D] Works offline

ANSWER: B

EXPLANATION:
  Figma MCP provides 3-10x fewer tokens than screenshots because it returns structured data (React+Tailwind structure, design tokens) instead of requiring image analysis. Other benefits: direct token access, component mapping via Code Connect, iterative workflow without new screenshots.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-016          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which Figma MCP tool retrieves design tokens (colors, spacing, typography)?

OPTIONS:
  [A] get_design_context
  [B] get_variable_defs ← ✓ CORRECT
  [C] get_metadata
  [D] get_screenshot

ANSWER: B

EXPLANATION:
  `get_variable_defs` retrieves design tokens like colors (--color-primary: #3B82F6), spacing (--spacing-md: 16px), and typography. Recommended workflow: get_metadata → get_design_context → get_variable_defs (once per project) → get_screenshot (only when visual reference needed).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-017          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What command adds the Figma MCP server for remote access?

OPTIONS:
  [A] claude mcp install figma
  [B] claude mcp add --transport http figma https://mcp.figma.com/mcp ← ✓ CORRECT
  [C] claude figma connect
  [D] npm install @figma/mcp

ANSWER: B

EXPLANATION:
  For remote MCP (all Figma plans, any machine): `claude mcp add --transport http figma https://mcp.figma.com/mcp`. For desktop MCP (requires Figma desktop app with Dev Mode): `claude mcp add --transport http figma-desktop http://127.0.0.1:3845/mcp`. Official Figma MCP was announced in 2025.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-018          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 2 core primitives of MCP Apps architecture?

OPTIONS:
  [A] Functions and Routes
  [B] Commands and Events
  [C] Tools with UI metadata and UI resources (ui:// scheme) ← ✓ CORRECT
  [D] Plugins and Themes

ANSWER: C

EXPLANATION:
  MCP Apps (SEP-1865) introduce 2 core primitives:
  
  1. **Tools with UI metadata** - Standard MCP tools annotated with rendering hints (input forms, output displays)
  2. **UI resources (ui:// scheme)** - Resources that return UI components instead of data
  
  Together, these allow MCP servers to provide both functionality and user interface, enabling richer agent-to-user interactions.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-019          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the 'auto:N' threshold control in MCP tool configuration?

OPTIONS:
  [A] Maximum concurrent MCP connections
  [B] Cache size for tool results
  [C] Automatic lazy loading when tool definitions exceed 10,000 tokens - tools discovered via Tool Search instead of loaded upfront ← ✓ CORRECT
  [D] Retry count for failed tool calls

ANSWER: C

EXPLANATION:
  When MCP tool definitions exceed 10,000 tokens, Claude Code automatically activates lazy loading. Instead of loading all tool definitions upfront, it marks them with 'defer_loading: true' and provides a Tool Search tool for on-demand discovery.
  
  When Claude needs a specific tool, it searches using keywords and selectively loads approximately 3-5 relevant tools (~3K tokens) per query. This dramatically reduces baseline context usage:
  
  **Example**: chrome-devtools MCP provides 26 tools consuming 17,000 tokens. With lazy loading configured for only 4 specific tools, it uses 1,500 tokens—a 91% reduction.
  
  **Important**: There is no configurable 'auto:N' parameter where N = max tools to load. The 10K token threshold triggers lazy loading automatically. Claude Code detects when tool descriptions surpass this threshold and switches to the Tool Search mechanism without manual configuration.
  
  This feature was introduced to address context pollution from MCP servers with many tools, most of which aren't frequently used.

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-020          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server scored highest (9.0/10) in the production ecosystem evaluation?

OPTIONS:
  [A] Playwright MCP (8.8/10)
  [B] Context7 MCP (8.5/10)
  [C] Semgrep MCP - SAST, secrets, and supply chain analysis ← ✓ CORRECT
  [D] Kubernetes MCP (8.4/10)

ANSWER: C

EXPLANATION:
  Semgrep MCP scored 9.0/10 in the production MCP ecosystem evaluation. It provides static application security testing (SAST), secrets detection, and supply chain analysis. Top scores: Semgrep (9.0), Playwright (8.8), Context7 (8.5), Kubernetes (8.4). Evaluation criteria: reliability, token efficiency, production readiness.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: MEMORY & SETTINGS
# 19 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the correct precedence order for CLAUDE.md files (highest to lowest priority)?

OPTIONS:
  [A] Global > Project > Local
  [B] Local (.claude/CLAUDE.md) > Project (/project/CLAUDE.md) > Global (~/.claude/CLAUDE.md) ← ✓ CORRECT
  [C] Project > Local > Global
  [D] All CLAUDE.md files have equal priority

ANSWER: B

EXPLANATION:
  The precedence is: Local (.claude/CLAUDE.md) > Project (/project/CLAUDE.md) > Global (~/.claude/CLAUDE.md). More specific beats more general. Local overrides are personal (gitignored), project settings are shared (committed), and global settings apply to all projects. This hierarchy allows personal preferences to override team conventions when needed.
  

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where should team conventions be stored to be shared via version control?

OPTIONS:
  [A] ~/.claude/CLAUDE.md
  [B] /project/.claude/CLAUDE.md
  [C] /project/CLAUDE.md ← ✓ CORRECT
  [D] /project/.claude/settings.local.json

ANSWER: C

EXPLANATION:
  Team conventions should be stored in `/project/CLAUDE.md` (the project root). This file is committed to git and shared with the team. Local overrides go in `/project/.claude/CLAUDE.md` (gitignored), and personal global preferences go in `~/.claude/CLAUDE.md`. This separation ensures team standards are enforced while allowing personal customization.
  

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the purpose of settings.local.json?

OPTIONS:
  [A] Store team hook configurations
  [B] Define project-wide settings
  [C] Personal permission overrides (gitignored) ← ✓ CORRECT
  [D] Configure MCP servers for the team

ANSWER: C

EXPLANATION:
  settings.local.json stores personal permission overrides and is gitignored. It allows you to customize which tools are auto-allowed, denied, or require asking for your personal workflow without affecting team settings. For example, you might allow all git commands while the team requires confirmation for certain operations.
  

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which folder contains custom agents, commands, hooks, and skills?

OPTIONS:
  [A] ~/.claude/
  [B] /project/CLAUDE.md
  [C] /project/.claude/ ← ✓ CORRECT
  [D] /project/config/

ANSWER: C

EXPLANATION:
  The `.claude/` folder in your project contains: agents/ (custom agent definitions), commands/ (custom slash commands), hooks/ (event-driven scripts), skills/ (knowledge modules), rules/ (auto-loaded conventions), and settings files. This is your project's Claude Code configuration directory for all extensions.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the permission behavior for tools listed in the 'deny' category?

OPTIONS:
  [A] Ask for confirmation each time
  [B] Auto-approve without asking
  [C] Block completely ← ✓ CORRECT
  [D] Log but allow

ANSWER: C

EXPLANATION:
  Tools in the 'deny' category are blocked completely - Claude cannot use them at all. The three permission behaviors are: 'allow' (auto-approve without asking), 'deny' (block completely), and 'ask' (prompt for confirmation). For example, denying "Bash(rm -rf *)" prevents accidental destructive operations.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-006          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Single Source of Truth Pattern' for multi-tool AI setups?

OPTIONS:
  [A] Use only one AI tool per project
  [B] Store conventions in docs/conventions/ and reference them from all AI tool configs ← ✓ CORRECT
  [C] Copy the same rules to each AI tool's config
  [D] Let each AI tool define its own rules

ANSWER: B

EXPLANATION:
  The Single Source of Truth Pattern stores conventions in `/docs/conventions/` (coding-standards.md, architecture.md, testing.md, etc.) and references them from CLAUDE.md, CodeRabbit, and other tools. This prevents conflicts where one tool approves code that another flags. All tools enforce the same standards from one source.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-007          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should be included in a project-level CLAUDE.md file?

OPTIONS:
  [A] Only personal preferences
  [B] Tech stack, code conventions, architecture patterns, and common commands ← ✓ CORRECT
  [C] API keys and secrets
  [D] Git history

ANSWER: B

EXPLANATION:
  Project CLAUDE.md should include: tech stack (frameworks, versions), code conventions (naming, patterns), architecture (folder structure, layers), and common commands (dev, test, lint). This gives Claude project context. Never include API keys or secrets. Keep it concise with examples, and update when conventions change.
  

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-008          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the permission pattern 'Bash(git *)' match?

OPTIONS:
  [A] Only the exact command 'git'
  [B] Any git command ← ✓ CORRECT
  [C] Git commands that start with asterisk
  [D] Git commands with glob patterns

ANSWER: B

EXPLANATION:
  The pattern 'Bash(git *)' matches any git command. Permission patterns use wildcards: 'Bash(git *)' matches any git command, 'Bash(pnpm *)' matches any pnpm command, 'mcp__serena__*' matches all Serena MCP tools. The space-based syntax is current - colon syntax like 'Bash(git status:*)' is deprecated.

OFFICIAL DOC: https://code.claude.com/docs/en/permissions

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-009          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Dynamic Memory' (Profile Switching)?

OPTIONS:
  [A] Claude's ability to remember across sessions
  [B] Temporarily modifying CLAUDE.md for specific tasks, then restoring ← ✓ CORRECT
  [C] Automatic memory compression
  [D] Syncing memory between devices

ANSWER: B

EXPLANATION:
  Dynamic Memory means temporarily modifying CLAUDE.md for specific tasks then restoring it. Techniques include: git stash (stash original, modify, restore), profile library (keep profiles like security-audit.md, debugging.md in ~/.claude/profiles/), or parallel instances (different CLAUDE.md in different worktrees). Switch profiles with a script: `claude-profile security-audit`.
  

OFFICIAL DOC: https://code.claude.com/docs/en/permissions

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-010          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What happens to files in the .claude/rules/ directory?

OPTIONS:
  [A] They must be manually imported
  [B] They are automatically loaded and combined ← ✓ CORRECT
  [C] They override CLAUDE.md
  [D] They are ignored unless referenced

ANSWER: B

EXPLANATION:
  Files in `.claude/rules/` are automatically loaded and combined. You can create multiple files like code-conventions.md, git-workflow.md, and architecture.md - all are loaded automatically without manual imports. This allows modular organization of project conventions that Claude will follow.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-011          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which of these should be gitignored?

OPTIONS:
  [A] /project/CLAUDE.md
  [B] .claude/agents/
  [C] .claude/settings.local.json and CLAUDE.local.md ← ✓ CORRECT
  [D] .claude/hooks/

ANSWER: C

EXPLANATION:
  Files that should be gitignored are: CLAUDE.local.md (local personal instructions) and .claude/settings.local.json (personal permissions). The .claude/CLAUDE.md file is project memory and should be committed. Files to commit include: agents/, commands/, hooks/, skills/, rules/, and settings.json. This separation allows personal customization while sharing team configurations.

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-012          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does 'allowedTools' configuration do differently from permission categories?

OPTIONS:
  [A] Nothing, they are the same
  [B] Provides granular control with tool-specific patterns in .claude/settings.json ← ✓ CORRECT
  [C] Only works for MCP tools
  [D] Requires admin privileges

ANSWER: B

EXPLANATION:
  The allowedTools configuration in .claude/settings.json or .claude/settings.local.json provides granular control with specific patterns. For example: 'Read(*)' allows all reads, 'Bash(git status *)' allows git status commands, 'Bash(pnpm *)' allows pnpm commands. You can set progressive permission levels from beginner (very restrictive) to advanced. Never use --dangerously-skip-permissions.

OFFICIAL DOC: https://code.claude.com/docs/en/permissions

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the global config path on macOS/Linux?

OPTIONS:
  [A] /etc/claude/
  [B] ~/.claude/ ← ✓ CORRECT
  [C] /usr/local/claude/
  [D] ~/.config/claude/

ANSWER: B

EXPLANATION:
  On macOS/Linux, the global config path is ~/.claude/. On Windows, it's %USERPROFILE%\.claude\ or C:\Users\YourName\.claude\. This directory contains your global CLAUDE.md, settings, and can include a profiles/ subdirectory for dynamic memory switching.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the three levels of progressive permission in allowedTools?

OPTIONS:
  [A] Admin, User, Guest
  [B] Beginner (very restrictive), Intermediate, Advanced ← ✓ CORRECT
  [C] Read, Write, Execute
  [D] Low, Medium, High

ANSWER: B

EXPLANATION:
  The three progressive permission levels are: Beginner (very restrictive - only Read, Grep, Glob), Intermediate (adds Bash git/pnpm, TodoRead/Write), and Advanced (adds Edit, Write, WebFetch, Task). Start restrictive and expand as you gain confidence. This prevents accidents while learning.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-015          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Why should you NEVER use --dangerously-skip-permissions?

OPTIONS:
  [A] It's deprecated
  [B] It can lead to destructive operations like rm -rf, force push to main, or DROP TABLE ← ✓ CORRECT
  [C] It costs more
  [D] It's slower

ANSWER: B

EXPLANATION:
  Never use --dangerously-skip-permissions because it can lead to destructive operations. Horror stories include: `rm -rf node_modules` followed by `rm -rf .` (path error), `git push --force` to main unintentionally, `DROP TABLE users` in poorly generated migrations, and deletion of .env files with credentials. Always prefer granular allowedTools instead.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-016          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should a global CLAUDE.md contain?

OPTIONS:
  [A] Project-specific code conventions
  [B] Personal preferences that apply to all projects (communication style, preferred tools, safety rules) ← ✓ CORRECT
  [C] Team member contact information
  [D] Git commit history

ANSWER: B

EXPLANATION:
  Global CLAUDE.md (~/.claude/CLAUDE.md) should contain personal preferences that apply to all your projects: communication style (be concise, use code examples), preferred tools (TypeScript over JavaScript, pnpm over npm), and safety rules (always run tests, never force push). Project-specific settings go in project CLAUDE.md.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-017          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is stored in settings.json (not settings.local.json)?

OPTIONS:
  [A] Personal permissions
  [B] Hook configurations that are committed to the repo ← ✓ CORRECT
  [C] API keys
  [D] Cost tracking data

ANSWER: B

EXPLANATION:
  settings.json stores hook configurations and is committed to the repo for team sharing. It defines hooks for PreToolUse, PostToolUse, UserPromptSubmit events - specifying matchers and hook scripts. Personal permission overrides go in settings.local.json (gitignored). This separation allows team automation while respecting personal preferences.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-018          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How many verification domains does the guide recommend for comprehensive quality checks?

OPTIONS:
  [A] 3 domains (lint, test, build)
  [B] 8 domains: frontend, backend, types, style, performance, accessibility, security, UX ← ✓ CORRECT
  [C] 5 domains: syntax, logic, performance, security, style
  [D] 12 domains covering every possible check

ANSWER: B

EXPLANATION:
  The Claude Code guide extends verification loops to 8 comprehensive domains for quality checks:
  
  1. Frontend (UI renders correctly)
  2. Backend (API responds correctly)
  3. Types (TypeScript/type checks pass)
  4. Style (linting passes)
  5. Performance (no regressions)
  6. Accessibility (WCAG compliance)
  7. Security (no vulnerabilities)
  8. UX (user flows work end-to-end)
  
  Note: Boris Cherny (Claude Code creator) emphasizes verification loops with 4 core methods: CLI tools (bash), Backend (tests), Frontend (browser), Mobile (simulator). The 8-domain taxonomy is the guide's expanded framework (v3.13.0).
  
  CLAUDE.md should define which domains to check for each type of change.

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-019          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Fresh Context Pattern' and when should you use it?

OPTIONS:
  [A] Clearing browser cache before testing
  [B] Starting a new session with clean context after implementation phase to avoid accumulated noise ← ✓ CORRECT
  [C] Resetting git to a clean state
  [D] Deleting the .claude folder to start fresh

ANSWER: B

EXPLANATION:
  The Fresh Context Pattern means starting a new Claude Code session between exploration and implementation phases. During exploration, context accumulates noise (dead ends, rejected approaches, debugging output). A fresh session gives Claude clean context focused purely on implementation, improving output quality.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: PRIVACY & OBSERVABILITY
# 11 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the default data retention period for Claude Code conversations?

OPTIONS:
  [A] 30 days
  [B] 1 year
  [C] 5 years ← ✓ CORRECT
  [D] Forever

ANSWER: C

EXPLANATION:
  Default retention is 5 years with data used for model training. By opting out of training at claude.ai/settings/data-privacy-controls, retention reduces to 30 days (safety monitoring only). Enterprise API (ZDR) has 0-day retention.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-002          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What data is sent to Anthropic when using Claude Code?

OPTIONS:
  [A] Only your prompts
  [B] Prompts, files Claude reads, MCP results, Bash outputs, error messages ← ✓ CORRECT
  [C] Only code snippets you copy-paste
  [D] Hashed metadata only

ANSWER: B

EXPLANATION:
  Everything Claude sees is sent: your prompts, files Claude reads (including .env if not excluded!), MCP server results (SQL queries, API responses), Bash command outputs, and error messages with stack traces. Use permissions.deny to block sensitive files.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-003          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the risk when connecting a database via MCP?

OPTIONS:
  [A] Database might slow down
  [B] Query results (including PII) are sent to Anthropic and stored per retention policy ← ✓ CORRECT
  [C] Claude might drop tables
  [D] MCP uses too many tokens

ANSWER: B

EXPLANATION:
  When MCP executes a database query, ALL results are sent to Anthropic: "SELECT * FROM orders" → 100 rows with customer names, emails, addresses → stored according to your retention tier. NEVER connect production databases. Use dev/staging with anonymized data.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How can you reduce Claude Code data retention from 5 years to 30 days?

OPTIONS:
  [A] Delete ~/.claude folder
  [B] Disable 'Allow model training' at claude.ai/settings/data-privacy-controls ← ✓ CORRECT
  [C] Use incognito mode
  [D] Add --no-retention flag

ANSWER: B

EXPLANATION:
  Visit claude.ai/settings/data-privacy-controls and toggle OFF "Allow model training". This immediately reduces retention from 5 years to 30 days (safety monitoring only). Enterprise API (ZDR) provides 0-day retention for HIPAA/GDPR compliance.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-005          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the Enterprise API (ZDR) data retention policy?

OPTIONS:
  [A] 30 days retention
  [B] 1 year retention
  [C] 0 days (real-time processing only, data not stored) ← ✓ CORRECT
  [D] 5 years like default

ANSWER: C

EXPLANATION:
  Enterprise API (Zero Data Retention) has 0-day retention - data is processed in real-time and not stored. Required for HIPAA, GDPR, PCI-DSS compliance and government contracts. Requires enterprise contract with Anthropic.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-006          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended session search tool from the guide?

OPTIONS:
  [A] claude-conversation-extractor
  [B] session-search.sh (zero-dependency bash script) ← ✓ CORRECT
  [C] ran CLI (npm)
  [D] Built-in /search command

ANSWER: B

EXPLANATION:
  session-search.sh is the recommended tool: zero dependencies (bash only), fast (~10ms list, ~400ms search), displays ready-to-use 'claude --resume' commands. Install with alias 'cs' for quick access. Alternative Python tools exist but are slower.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-007          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What hook event is used for session logging?

OPTIONS:
  [A] PreToolUse
  [B] PostToolUse ← ✓ CORRECT
  [C] SessionStart
  [D] Notification

ANSWER: B

EXPLANATION:
  Session logging uses PostToolUse hook - it runs after each tool completes, capturing tool name, file path, project, and token estimates. Configure in settings.json with the session-logger.sh script. Logs are stored as JSONL files in ~/.claude/logs/.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-008          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the token estimation method used by the session logger?

OPTIONS:
  [A] API-provided exact counts
  [B] ~4 characters per token (heuristic, slightly overestimates) ← ✓ CORRECT
  [C] 1 word = 1 token
  [D] Based on file size only

ANSWER: B

EXPLANATION:
  The logger estimates tokens using ~4 characters per token heuristic. This is approximate and tends to slightly overestimate. Claude Code CLI doesn't expose actual API token metrics, so estimates have ~15-25% variance from actual billing.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-009          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What CANNOT the session monitoring do?

OPTIONS:
  [A] Track tool usage counts
  [B] Identify file access patterns
  [C] Provide exact token counts and actual API costs ← ✓ CORRECT
  [D] Record operation timestamps

ANSWER: C

EXPLANATION:
  Monitoring CANNOT provide: exact token counts (CLI doesn't expose API metrics), actual API costs (estimates only), TTFT timing, real-time streaming metrics, or context window usage. It CAN track: tool usage counts, file access patterns, relative comparisons, operation timing.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where are Claude Code session logs stored locally?

OPTIONS:
  [A] ~/.config/claude/
  [B] ~/.claude/projects/<project>/ ← ✓ CORRECT
  [C] /var/log/claude/
  [D] In the cloud only

ANSWER: B

EXPLANATION:
  Sessions are stored locally at ~/.claude/projects/<project>/ as JSONL files. This enables session resume with 'claude --resume <id>' or 'claude -c' for most recent. Custom logs from session-logger.sh go to ~/.claude/logs/ (configurable via CLAUDE_LOG_DIR).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 14-011          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you use 'Co-Authored-By' vs 'Assisted-By' in git commits?

OPTIONS:
  [A] Always use Co-Authored-By for any AI involvement
  [B] Co-Authored-By when AI generated significant code, Assisted-By when AI only advised or reviewed ← ✓ CORRECT
  [C] Never attribute AI in commits
  [D] Use both on every commit

ANSWER: B

EXPLANATION:
  AI traceability in git commits:
  
  - **Co-Authored-By**: When AI generated significant portions of code (implementation, refactoring)
  - **Assisted-By**: When AI only advised, reviewed, or suggested minor changes
  
  This distinction matters for code ownership, audit trails, and understanding who (or what) actually wrote the code. Some teams add this to CLAUDE.md as a mandatory commit convention.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: QUICK START
# 18 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended universal method to install Claude Code?

OPTIONS:
  [A] brew install claude-code
  [B] npm install -g @anthropic-ai/claude-code
  [C] pip install claude-code
  [D] curl -fsSL https://claude.ai/install.sh | sh ← ✓ CORRECT

ANSWER: D

EXPLANATION:
  The recommended installation method is `curl -fsSL https://claude.ai/install.sh | sh` which works across all platforms. npm is deprecated - use `claude install` to migrate if you installed via npm. While Homebrew is available for macOS, the shell script is the universal method recommended in official docs.

OFFICIAL DOC: https://code.claude.com/docs/en/setup

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  After Claude proposes a code change, what options do you have when reviewing the diff?

OPTIONS:
  [A] Only accept (y) or reject (n)
  [B] Accept (y), reject (n), or edit (e) ← ✓ CORRECT
  [C] Accept (y), skip (s), or delay (d)
  [D] Commit (c), reject (r), or review (v)

ANSWER: B

EXPLANATION:
  When Claude proposes a change, you have three options: press 'y' to accept the change, 'n' to reject and ask for alternatives, or 'e' to edit the change manually. This gives you full control over what gets applied to your codebase. Always review diffs before accepting - this is your safety net.
  

OFFICIAL DOC: https://code.claude.com/docs/en/interactive-mode

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-003          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which command shows all available Claude Code commands?

OPTIONS:
  [A] /commands
  [B] /list
  [C] /help ← ✓ CORRECT
  [D] /menu

ANSWER: C

EXPLANATION:
  The `/help` command displays all available Claude Code commands. This is the go-to command when you're lost or want to discover available functionality. It's one of the 7 essential commands that cover 90% of daily usage.
  

OFFICIAL DOC: https://code.claude.com/docs/en/slash-commands

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the `!` prefix do in Claude Code?

OPTIONS:
  [A] Marks a command as urgent
  [B] Runs a shell command directly without asking Claude ← ✓ CORRECT
  [C] Escapes special characters
  [D] Deletes the previous command

ANSWER: B

EXPLANATION:
  The `!` prefix executes shell commands immediately without asking Claude to do it. For example, `!git status` runs the command directly. Use this for quick status checks, view commands, and already-known commands. It's faster than asking Claude when you know exactly what command you need.
  

OFFICIAL DOC: https://code.claude.com/docs/en/interactive-mode

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-005          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the `@` symbol do when used in a prompt?

OPTIONS:
  [A] Mentions another user
  [B] References a specific file for targeted operations ← ✓ CORRECT
  [C] Tags a message as important
  [D] Activates an agent

ANSWER: B

EXPLANATION:
  The `@` symbol references specific files in your prompts for targeted operations. For example, `Review @src/auth/login.tsx for security issues` signals Claude to read that file. This provides precision (target exact files), speed (skip file discovery), and clarity (makes your intent explicit). Claude reads the file on-demand via tools.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-006          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended approach when migrating from GitHub Copilot to Claude Code?

OPTIONS:
  [A] Completely stop using Copilot immediately
  [B] Use a hybrid approach: Copilot for autocomplete, Claude Code for complex tasks ← ✓ CORRECT
  [C] Only use Claude Code for simple tasks
  [D] Export all Copilot settings to Claude Code

ANSWER: B

EXPLANATION:
  The guide recommends a hybrid approach: use Copilot for quick autocomplete and boilerplate while using Claude Code for feature implementation, debugging, code reviews, and understanding unfamiliar codebases. This leverages the strengths of both tools - Copilot excels at inline suggestions while Claude Code handles multi-file operations and complex reasoning.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-007          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In Plan Mode, what is Claude allowed to do?

OPTIONS:
  [A] Edit files, run commands, and make commits
  [B] Only read and analyze - no modifications allowed ← ✓ CORRECT
  [C] Run commands but not edit files
  [D] Create new files but not edit existing ones

ANSWER: B

EXPLANATION:
  Plan Mode is Claude Code's "look but don't touch" mode. It allows reading files, searching the codebase, analyzing architecture, and proposing approaches. It prevents editing files, running state-modifying commands, creating new files, and making commits. Perfect for safe exploration before making changes.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-008          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What flag allows you to continue your most recent Claude Code conversation?

OPTIONS:
  [A] --last
  [B] --continue or -c ← ✓ CORRECT
  [C] --resume-last
  [D] --restore

ANSWER: B

EXPLANATION:
  Use `claude --continue` or `claude -c` to automatically resume your most recent conversation. This maintains full context and conversation history across terminal sessions. For resuming a specific session by ID, use `claude --resume <id>` or `claude -r <id>`. This is particularly useful for multi-day features or when interrupted.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-009          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should you ALWAYS do before accepting a code change from Claude?

OPTIONS:
  [A] Run the test suite
  [B] Create a backup of the file
  [C] Read the diff carefully ← ✓ CORRECT
  [D] Ask for Claude's confidence level

ANSWER: C

EXPLANATION:
  Always read the diff before accepting changes - this is your safety net. The guide emphasizes this as critical: "Always review diffs before accepting changes." While running tests is good practice, reviewing the diff is the immediate required step before any acceptance. You need to understand what changes are being proposed.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which keyboard shortcut cancels the current operation in Claude Code?

OPTIONS:
  [A] Ctrl+Z
  [B] Ctrl+C ← ✓ CORRECT
  [C] Esc
  [D] Ctrl+Q

ANSWER: B

EXPLANATION:
  Ctrl+C cancels the current operation in Claude Code. This is useful for stopping long-running analysis or when Claude is taking an approach you don't want. Esc dismisses the current suggestion, while Ctrl+R retries the last operation. Knowing these shortcuts helps maintain control during your workflow.
  

OFFICIAL DOC: https://code.claude.com/docs/en/interactive-mode

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you use auto-accept mode in Claude Code?

OPTIONS:
  [A] For all operations to save time
  [B] Only for well-defined, reversible operations you trust ← ✓ CORRECT
  [C] When working on production code
  [D] For complex refactoring tasks

ANSWER: B

EXPLANATION:
  Auto-accept mode should only be used for well-defined, reversible operations. The guide warns: "Only use auto-accept for well-defined, reversible operations." It's dangerous for complex or risky changes. Default mode (asking permission) is safest, especially for learning and production work.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-012          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended rule of thumb for choosing between Claude Code and autocomplete tools based on code size?

OPTIONS:
  [A] <10 lines: autocomplete, >10 lines: Claude Code
  [B] <5 lines: autocomplete, 5-50 lines single file: either, >50 lines or multi-file: Claude Code ← ✓ CORRECT
  [C] Always use Claude Code regardless of size
  [D] <20 lines: autocomplete, >20 lines: Claude Code

ANSWER: B

EXPLANATION:
  The guide provides clear guidance: less than 5 lines of code - use Copilot/autocomplete; 5-50 lines in a single file - either tool works; more than 50 lines or multi-file changes - use Claude Code. This helps you choose the right tool for the task's complexity level.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What image formats does Claude Code support for visual analysis?

OPTIONS:
  [A] Only PNG
  [B] PNG, JPG, JPEG, WebP, GIF (static) ← ✓ CORRECT
  [C] All image formats including RAW
  [D] SVG and PNG only

ANSWER: B

EXPLANATION:
  Claude Code supports PNG, JPG, JPEG, WebP, and static GIF formats. You can paste images directly in the terminal (Cmd+V/Ctrl+V), drag and drop, or reference by path. This is useful for implementing UI from mockups, debugging visual issues, analyzing diagrams, and accessibility audits. Note that images consume significant context tokens (1000-2000 words equivalent).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When resuming a Claude Code session, what context is preserved?

OPTIONS:
  [A] Only the conversation history
  [B] Full conversation history, files read/edited, CLAUDE.md settings ← ✓ CORRECT
  [C] Just the last 10 messages
  [D] Only files that were modified

ANSWER: B

EXPLANATION:
  When you resume a session, Claude retains: full conversation history, files previously read/edited, CLAUDE.md and project settings, and uncommitted code changes awareness. MCP servers restart on each session - their state is NOT preserved. Session-scoped permissions also don't carry over.

OFFICIAL DOC: https://code.claude.com/docs/en/how-claude-code-works

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-015          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What command should you use to verify Claude Code installation?

OPTIONS:
  [A] claude check
  [B] claude --verify
  [C] claude --version ← ✓ CORRECT
  [D] claude test

ANSWER: C

EXPLANATION:
  Use `claude --version` to verify your installation and display the current version. This is also useful before reporting bugs. After installation, you can also use `claude doctor` to verify auto-updater health and `claude update` to check for available updates.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-016          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the optimal image resolution range for Claude Code visual analysis?

OPTIONS:
  [A] 50-200px (smallest possible)
  [B] 200-1568px (sweet spot for quality/token balance) ← ✓ CORRECT
  [C] 2000-4000px (maximum detail)
  [D] 8000px+ (highest resolution)

ANSWER: B

EXPLANATION:
  The optimal range is 200-1568px. Below 200px lacks detail, 200-1000px is the sweet spot for wireframes, 1000-1568px provides optimal quality/token balance, images above 1568px are auto-downscaled (wasting upload time), and images over 8000px are rejected by the API.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-017          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How are image tokens calculated in Claude Code?

OPTIONS:
  [A] file_size_bytes / 1000
  [B] (width × height) / 750 ← ✓ CORRECT
  [C] pixels / 1000
  [D] Fixed 500 tokens per image

ANSWER: B

EXPLANATION:
  Token calculation formula: (width × height) / 750 ≈ tokens consumed. Examples: 200×200 = ~54 tokens, 500×500 = ~334 tokens, 1000×1000 = ~1334 tokens. This helps estimate context impact before pasting images. Use /status after pasting to monitor actual context usage.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-018          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which image format is recommended for wireframes and diagrams in Claude Code?

OPTIONS:
  [A] JPEG (best compression)
  [B] PNG (sharp lines and text) ← ✓ CORRECT
  [C] GIF (universal support)
  [D] BMP (lossless)

ANSWER: B

EXPLANATION:
  PNG is recommended for wireframes, diagrams, and text because it preserves sharp lines. WebP is good for general screenshots with compression. JPEG is for photos only—compression artifacts harm line detection. GIF should be avoided (static only, poor quality). Always crop to relevant area and resize to 1000-1200px if larger.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: REFERENCE
# 20 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What keyboard shortcut enters Plan Mode (toggles plan/execute)?

OPTIONS:
  [A] Ctrl+P
  [B] Shift+Tab ← ✓ CORRECT
  [C] Alt+P
  [D] Ctrl+Shift+P

ANSWER: B

EXPLANATION:
  `Shift+Tab` toggles between Plan Mode and Execute Mode.
  
  Plan Mode navigation:
  - `Shift+Tab` once: Toggle plan/execute
  - `Shift+Tab` twice: Enter deep Plan Mode (with Opus in OpusPlan)
  
  Plan Mode allows safe, read-only exploration before making changes.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What keyboard shortcut rewinds to a previous checkpoint (undo Claude's changes)?

OPTIONS:
  [A] Ctrl+Z
  [B] Esc (double-tap) ← ✓ CORRECT
  [C] Ctrl+R
  [D] Alt+Z

ANSWER: B

EXPLANATION:
  Double-tap `Esc` (Esc×2) rewinds to the previous checkpoint.
  
  This is equivalent to the `/rewind` command.
  It undoes Claude's recent changes in the current session without creating git commits.
  
  Use when Claude made a mistake and you want to try a different approach.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-003          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does `/compact` do?

OPTIONS:
  [A] Compresses files on disk
  [B] Summarizes and compresses the conversation context ← ✓ CORRECT
  [C] Minimizes the terminal window
  [D] Reduces Claude's response length

ANSWER: B

EXPLANATION:
  `/compact` summarizes and compresses the conversation context.
  
  Use `/compact` when:
  - Context usage reaches 70-90%
  - Responses become slow
  - Claude starts forgetting earlier context
  
  This frees up context space while preserving important information.
  Check context usage with `/status`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-004          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  At what context percentage should you run /compact according to best practices?

OPTIONS:
  [A] 50%
  [B] 70-90% ← ✓ CORRECT
  [C] 95%+
  [D] Only when errors occur

ANSWER: B

EXPLANATION:
  Context management guidelines:
  
  | Context Level | Action |
  |--------------|--------|
  | 0-50% | Work freely |
  | 50-75% | Be selective |
  | **75-90%** | **Use `/compact`** |
  | 90%+ | Use `/clear` |
  
  Proactive compaction at 70% prevents context degradation and maintains performance.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-006          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the correct permission pattern to allow ALL git commands?

OPTIONS:
  [A] Bash(git)
  [B] Bash(git *) ← ✓ CORRECT
  [C] git:*
  [D] Bash(*git*)

ANSWER: B

EXPLANATION:
  The pattern `Bash(git *)` allows any git command.
  
  Permission pattern examples:
  - `Bash(git *)` - Any git command
  - `Bash(npm test)` - Exactly "npm test"
  - `Edit` - All file edits
  - `mcp__serena__*` - All Serena tools
  
  Wildcards (*) enable flexible permission matching.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-007          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where should project-specific CLAUDE.md be placed (committed to git)?

OPTIONS:
  [A] ~/.claude/CLAUDE.md
  [B] /project/.claude/CLAUDE.md
  [C] /project/CLAUDE.md ← ✓ CORRECT
  [D] ~/.config/claude/project.md

ANSWER: C

EXPLANATION:
  CLAUDE.md locations:
  
  | Location | Scope | Committed |
  |----------|-------|-----------|
  | `~/.claude/CLAUDE.md` | All projects | N/A (global) |
  | `/project/CLAUDE.md` | This project | **Yes** |
  | `/project/.claude/CLAUDE.md` | Personal | No |
  
  The root `CLAUDE.md` is committed and shared with the team.
  The `.claude/CLAUDE.md` is personal and should be in `.gitignore`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-008          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the --mcp-debug flag do?

OPTIONS:
  [A] Disables MCP servers
  [B] Debugs MCP server connections with verbose output ← ✓ CORRECT
  [C] Tests MCP configurations
  [D] Enables MCP auto-discovery

ANSWER: B

EXPLANATION:
  The `--mcp-debug` flag enables debug mode for MCP server connections.
  
  MCP debugging techniques:
  ```bash
  claude --mcp-debug  # Debug all MCP connections
  /mcp               # View MCP status inside Claude Code
  ```
  
  Use when MCP servers aren't connecting or tools aren't appearing.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-009          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  If an MCP server name validation fails with pattern error, what characters ARE allowed?

OPTIONS:
  [A] Letters only
  [B] Letters, numbers, underscores, hyphens (max 64 chars) ← ✓ CORRECT
  [C] Any characters except spaces
  [D] Alphanumeric and periods

ANSWER: B

EXPLANATION:
  MCP server names must match: `^[a-zA-Z0-9_-]{1,64}`
  
  Allowed:
  - Letters (a-z, A-Z)
  - Numbers (0-9)
  - Underscores (_)
  - Hyphens (-)
  - Maximum 64 characters
  
  Not allowed:
  - Spaces
  - Special characters (@, #, etc.)
  - More than 64 characters
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What command shows session info including context usage and cost?

OPTIONS:
  [A] /info
  [B] /status ← ✓ CORRECT
  [C] /stats
  [D] /session

ANSWER: B

EXPLANATION:
  The `/status` command shows session information.
  
  Output includes:
  - Model being used
  - Context usage percentage
  - Session cost
  - Token counts
  
  Example output:
  `Model: Sonnet | Ctx: 45.2k | Cost: $1.23 | Ctx(u): 42.0%`
  
  Use `/stats` for usage statistics with activity graphs.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What flag limits maximum API spend in headless mode?

OPTIONS:
  [A] --cost-limit
  [B] --max-budget-usd ← ✓ CORRECT
  [C] --spending-cap
  [D] --budget

ANSWER: B

EXPLANATION:
  The `--max-budget-usd` flag sets maximum API spend (only with `--print`):
  
  ```bash
  claude -p "analyze" --max-budget-usd 5.00
  ```
  
  This prevents runaway costs in automated pipelines.
  The operation stops if the budget is exceeded.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-012          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you run a shell command directly from Claude Code prompt?

OPTIONS:
  [A] shell: command
  [B] !command ← ✓ CORRECT
  [C] $command
  [D] run command

ANSWER: B

EXPLANATION:
  The `!command` prefix runs a shell command directly.
  
  Quick actions:
  - `!command` - Run shell command
  - `@filename` - Reference file
  - `Ctrl+C` - Cancel operation
  - `Ctrl+R` - Retry last
  
  Example: `!git status` runs git status without Claude interpreting it.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-013          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the correct way to resume a specific session by ID?

OPTIONS:
  [A] claude --session abc123
  [B] claude -r abc123 ← ✓ CORRECT
  [C] claude --load abc123
  [D] claude -s abc123

ANSWER: B

EXPLANATION:
  Use `-r` or `--resume` to resume a specific session:
  
  ```bash
  claude -r abc123           # Resume session abc123
  claude --resume abc123     # Same as above
  claude -c                  # Resume last session (short)
  claude --continue          # Resume last session (long)
  ```
  
  Combine with `-p` for scripting: `claude -r abc123 -p "check status"`
  

OFFICIAL DOC: https://code.claude.com/docs/en/setup

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-014          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended .gitignore pattern for Claude Code files?

OPTIONS:
  [A] Ignore all .claude/ contents
  [B] Ignore settings.local.json and CLAUDE.local.md, keep agents/commands/hooks ← ✓ CORRECT
  [C] Don't ignore anything
  [D] Ignore only agents/

ANSWER: B

EXPLANATION:
  Recommended .gitignore:
  
  ```gitignore
  # Claude Code - Personal (ignore)
  .claude/settings.local.json
  CLAUDE.local.md
  .claude/.serena/
  
  # Claude Code - Team (keep/commit)
  # .claude/CLAUDE.md (project memory)
  # .claude/agents/
  # .claude/commands/
  # .claude/hooks/
  # .claude/settings.json
  ```
  
  This keeps team workflows shared while personal settings stay private.

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-015          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the daily workflow morning setup according to the guide?

OPTIONS:
  [A] Just start coding
  [B] Git pull, /status, load project memory, review yesterday's progress ← ✓ CORRECT
  [C] Run all tests first
  [D] Clear all context

ANSWER: B

EXPLANATION:
  Morning setup workflow:
  
  1. Git pull latest changes
  2. Review context with `/status`
  3. Load project memory (`/sc:load` if using Serena)
  4. Review yesterday's progress
  
  This ensures you start with fresh code and full context awareness.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-016          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What flag allows Claude's tools to access directories outside the current working directory?

OPTIONS:
  [A] --include-dir
  [B] --add-dir ← ✓ CORRECT
  [C] --context-dir
  [D] --load-dir

ANSWER: B

EXPLANATION:
  Use `--add-dir` to allow tool access to additional directories:
  
  ```bash
  claude --add-dir ../shared ../utils
  claude --add-dir packages/api
  ```
  
  By default, Claude can only access files in the current working directory.
  Use --add-dir to extend permissions to other directories (e.g., shared libraries in a monorepo).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-017          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When Sequential Thinking MCP seems slow or unresponsive, what should you expect?

OPTIONS:
  [A] It's broken and needs restart
  [B] 10-30 second responses are normal due to significant compute ← ✓ CORRECT
  [C] Switch to a different MCP
  [D] Reduce the query complexity

ANSWER: B

EXPLANATION:
  Sequential Thinking uses significant compute - expect 10-30 second responses.
  
  This is not an error, just be patient.
  
  Tips for Sequential:
  - Works best with specific, well-defined problems
  - Good: "Debug why user authentication fails on mobile"
  - Bad: "Make the app better"
  
  The longer response time reflects deeper analysis.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-018          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What shortcut opens an external editor for composing long text input?

OPTIONS:
  [A] Ctrl+E
  [B] Ctrl+G ← ✓ CORRECT
  [C] Ctrl+O
  [D] Ctrl+L

ANSWER: B

EXPLANATION:
  `Ctrl+G` opens an external editor for composing long text.
  
  Useful input shortcuts:
  - `Ctrl+A`: Jump to beginning of line
  - `Ctrl+E`: Jump to end of line
  - `Ctrl+W`: Delete previous word
  - `Ctrl+G`: Open external editor
  - `Tab`: Autocomplete file paths
  
  The external editor allows comfortable editing of complex prompts.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-019          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the '--from-pr' flag do in Claude Code v2.1.27?

OPTIONS:
  [A] Creates a new pull request
  [B] Resumes sessions linked to a GitHub PR number or URL ← ✓ CORRECT
  [C] Fetches all PR comments into context
  [D] Closes a pull request

ANSWER: B

EXPLANATION:
  The `--from-pr` flag (v2.1.27) lets you resume Claude Code sessions linked to a specific GitHub PR. Usage: `claude --from-pr 123` or `claude --from-pr https://github.com/org/repo/pull/123`. This loads the PR context (diff, comments, checks) directly into the session.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-020          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What breaking change was introduced in Claude Code v2.1.19 for hook/command arguments?

OPTIONS:
  [A] Arguments removed entirely
  [B] Migration from $ARGUMENTS.0 (dot syntax) to $ARGUMENTS[0] (bracket syntax) ← ✓ CORRECT
  [C] New $PARAMS variable replaced $ARGUMENTS
  [D] Arguments now require JSON format

ANSWER: B

EXPLANATION:
  Claude Code v2.1.19 changed argument access syntax from dot notation (`$ARGUMENTS.0`) to bracket notation (`$ARGUMENTS[0]`). This breaking change affects all custom commands and hooks that reference arguments. Update your scripts to use the new bracket syntax.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-021          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  According to the guide's 'Myths vs Reality' section, what is the truth about 'hidden Claude Code features'?

OPTIONS:
  [A] Secret flags exist for power users
  [B] Hidden features require an enterprise plan
  [C] There are no hidden features - Anthropic uses progressive rollout, not secret flags ← ✓ CORRECT
  [D] Beta flags are stored in .claude/config

ANSWER: C

EXPLANATION:
  The Myths vs Reality section debunks the "hidden features" myth. Anthropic uses progressive rollout (features gradually enabled for users) rather than secret flags or hidden configurations. All features are documented in release notes. There is no secret power-user mode.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: SECURITY HARDENING
# 12 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-001          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is an 'MCP Rug Pull' attack?

OPTIONS:
  [A] An MCP server that crashes unexpectedly
  [B] A benign MCP that turns malicious after gaining trust (no re-approval needed) ← ✓ CORRECT
  [C] An MCP that uses too many tokens
  [D] An attack on the MCP protocol itself

ANSWER: B

EXPLANATION:
  An MCP Rug Pull exploits the one-time approval model: attacker publishes benign MCP → user approves once → MCP works normally (builds trust) → attacker pushes malicious update → MCP exfiltrates credentials WITHOUT re-approval. Mitigation: version pinning + hash verification.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-002          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does CVE-2025-53109/53110 (EscapeRoute) exploit?

OPTIONS:
  [A] Prompt injection in Claude's system prompt
  [B] Filesystem MCP sandbox escape via prefix bypass + symlinks ← ✓ CORRECT
  [C] Memory corruption in the Bash tool
  [D] API key leakage in network requests

ANSWER: B

EXPLANATION:
  CVE-2025-53109/53110 (EscapeRoute) allows sandbox escape in Filesystem MCP via prefix bypass combined with symlinks. Severity: High. Mitigation: avoid Filesystem MCP with unrestricted access or apply the official patch. Source: Cymulate security research.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-003          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a known limitation of permissions.deny in .claude/settings.json?

OPTIONS:
  [A] It only works on macOS
  [B] System reminders may expose file contents before tool permission checks ← ✓ CORRECT
  [C] It cannot block Bash commands
  [D] It requires admin privileges

ANSWER: B

EXPLANATION:
  permissions.deny has architectural limitations: background indexing may expose file contents via internal "system reminder" mechanism BEFORE tool permission checks are applied. This is documented in GitHub #4160. Defense-in-depth: store secrets outside project directories.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-004          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended defense-in-depth strategy for secrets protection?

OPTIONS:
  [A] Only use permissions.deny
  [B] Store secrets outside project + external vault + PreToolUse hooks + never commit ← ✓ CORRECT
  [C] Encrypt all files in the project
  [D] Use a VPN when running Claude Code

ANSWER: B

EXPLANATION:
  Defense-in-depth: (1) Store secrets outside project directories (~/.secrets/ or vault), (2) Use external secrets management (AWS Secrets Manager, 1Password), (3) Add PreToolUse hooks as secondary blocking, (4) Never commit secrets, (5) Manually review bash commands.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which prompt injection evasion technique uses U+200B, U+200C, U+200D?

OPTIONS:
  [A] Base64 encoding
  [B] RTL override
  [C] Zero-width characters (invisible to humans) ← ✓ CORRECT
  [D] Homoglyphs

ANSWER: C

EXPLANATION:
  Zero-width characters (U+200B, U+200C, U+200D) make instructions invisible to humans while still being interpreted. Detection: Unicode regex pattern [\x{200B}-\x{200D}\x{FEFF}\x{202A}-\x{202E}]. Added to prompt-injection-detector.sh in v3.6.0.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-006          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which secret detection tool has the highest recall (88%) but lower precision (46%)?

OPTIONS:
  [A] TruffleHog
  [B] GitGuardian
  [C] Gitleaks ← ✓ CORRECT
  [D] detect-secrets

ANSWER: C

EXPLANATION:
  Gitleaks: 88% recall, 46% precision, fast (~2 min/100K commits) - best for pre-commit hooks. TruffleHog: 52% recall, 85% precision, slow - best for CI verification. GitGuardian: 80% recall, 95% precision - enterprise monitoring. detect-secrets: 60% recall, 98% precision - baseline approach.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-007          Difficulty: intermediate         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended hook stack for security in settings.json?

OPTIONS:
  [A] Only PostToolUse hooks for logging
  [B] PreToolUse (dangerous blocker, injection detector) + PostToolUse (output scanner) + SessionStart (MCP integrity) ← ✓ CORRECT
  [C] No hooks - rely only on permissions.deny
  [D] Only UserPromptSubmit hooks

ANSWER: B

EXPLANATION:
  Recommended security hook stack: PreToolUse → dangerous-actions-blocker.sh (Bash), prompt-injection-detector.sh + unicode-injection-scanner.sh (Edit/Write). PostToolUse → output-secrets-scanner.sh (Bash). SessionStart → mcp-config-integrity.sh. Multiple layers for defense-in-depth.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-008          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP servers are marked as 'Safe' in the community-vetted safe list?

OPTIONS:
  [A] filesystem (unrestricted), database (prod credentials)
  [B] @anthropic/mcp-server-*, context7, sequential-thinking, memory ← ✓ CORRECT
  [C] browser (full access), custom MCPs
  [D] All MCPs are safe by default

ANSWER: B

EXPLANATION:
  MCP Safe List: @anthropic/mcp-server-* (official), context7 (read-only docs), sequential-thinking (no external access, local), memory (local file-based). Risk: filesystem unrestricted (CVE-2025-53109), database prod (exfiltration). Unsafe: browser full access.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-009          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the first action when a secret is exposed?

OPTIONS:
  [A] Document the incident for post-mortem
  [B] Revoke the credential immediately ← ✓ CORRECT
  [C] Scan the entire repo
  [D] Notify the team

ANSWER: B

EXPLANATION:
  First 15 minutes (stop the bleeding): (1) Revoke immediately - AWS delete-access-key, GitHub revoke token, Stripe roll key. (2) Confirm exposure scope. Then: audit git history, scan dependencies, check CI/CD logs. First 24 hours: rotate ALL related credentials, notify compliance, document timeline.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the three security posture levels in the guide?

OPTIONS:
  [A] Low, Medium, High
  [B] Basic (5 min), Standard (30 min), Hardened (2 hours) ← ✓ CORRECT
  [C] Development, Staging, Production
  [D] Free, Pro, Enterprise

ANSWER: B

EXPLANATION:
  Security posture levels: Basic (5 min) = output scanner + dangerous blocker - for solo dev/experiments. Standard (30 min) = + injection hooks + MCP vetting - for teams/sensitive code. Hardened (2 hours) = + integrity verification + ZDR - for enterprise/production.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-011          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which sandbox isolation approach combines microVM isolation with network policies for agent autonomy?

OPTIONS:
  [A] E2B (hosted cloud sandboxes)
  [B] Fly.io Sprites (edge compute)
  [C] Docker Sandboxes (with custom templates and network policies) ← ✓ CORRECT
  [D] Cloudflare Sandbox SDK

ANSWER: C

EXPLANATION:
  Docker Sandboxes provide microVM-level isolation with customizable network policies. Key features: custom Dockerfile templates for reproducible environments, network policies to control egress/ingress, volume mounts for persistent storage, and CPU/memory limits. This approach suits teams wanting full control over sandbox configuration while maintaining strong isolation.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 13-012          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the GitHub Issue Auto-Creation Bug (#13797) and why is it dangerous?

OPTIONS:
  [A] Issues get automatically deleted
  [B] Claude Code accidentally creates public GitHub issues containing private project details ← ✓ CORRECT
  [C] Issues are created but remain private
  [D] Only affects paid enterprise accounts

ANSWER: B

EXPLANATION:
  The GitHub Issue Auto-Creation Bug (#13797) causes Claude Code to accidentally create public GitHub issues containing private project details. Over 17 accidental disclosures documented, affecting v2.0.65+. The danger: internal code, architecture decisions, and private context leak publicly. Mitigation: disable the gh CLI tool or restrict GitHub permissions.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: SKILLS
# 18 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-001          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the relationship between Skills and Agents?

OPTIONS:
  [A] Skills replace agents
  [B] Skills are knowledge packages that agents can inherit ← ✓ CORRECT
  [C] Agents are a type of skill
  [D] They are completely independent

ANSWER: B

EXPLANATION:
  Skills are knowledge packages that agents can inherit. While agents are specialized roles (task-focused), skills are reusable knowledge modules (domain-focused). Multiple agents can inherit the same skill, avoiding duplication. For example, both a code-reviewer and security-auditor agent can inherit the security-guardian skill.
  

OFFICIAL DOC: https://code.claude.com/docs/en/skills

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-002          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Where should skill files be stored?

OPTIONS:
  [A] .claude/commands/
  [B] .claude/skills/{skill-name}/ ← ✓ CORRECT
  [C] .claude/agents/
  [D] ~/.claude/skills/

ANSWER: B

EXPLANATION:
  Skills live in `.claude/skills/{skill-name}/` directories within your project. Each skill has its own folder containing at minimum a SKILL.md file, with optional reference.md, checklists/, examples/, and scripts/ subdirectories. This organization keeps knowledge modular and reusable.
  

OFFICIAL DOC: https://code.claude.com/docs/en/skills

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-003          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the REQUIRED file in a skill folder?

OPTIONS:
  [A] README.md
  [B] skill.yaml
  [C] SKILL.md ← ✓ CORRECT
  [D] index.md

ANSWER: C

EXPLANATION:
  SKILL.md is the required main file in every skill folder. Optional files include: reference.md (detailed documentation), checklists/ (verification lists), examples/ (code patterns with good/bad examples), and scripts/ (helper scripts). SKILL.md contains the frontmatter and core instructions for the skill.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-004          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the key difference between Skills, Agents, and Commands?

OPTIONS:
  [A] They all do the same thing
  [B] Skills = knowledge modules (inherited), Agents = specialized roles (delegated), Commands = process workflows (slash invoked) ← ✓ CORRECT
  [C] Commands are the only reusable component
  [D] Agents cannot use skills or commands

ANSWER: B

EXPLANATION:
  The three concepts have distinct purposes: Skills are knowledge modules inherited by agents (like OWASP security knowledge), Agents are specialized roles that Claude delegates tasks to (like a security reviewer), and Commands are process workflows invoked with slash commands (like /tech:commit). They can be combined: agents inherit skills and execute commands.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-005          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the 'context' field in SKILL.md frontmatter control?

OPTIONS:
  [A] The context window size
  [B] Whether the skill runs in isolated (fork) or shared (inherit) context ← ✓ CORRECT
  [C] The file context to load
  [D] Database connection context

ANSWER: B

EXPLANATION:
  The `context` field controls execution context: 'fork' means isolated context (the skill runs independently), 'inherit' means shared context (the skill shares context with the calling agent). Use fork for skills that need clean state, inherit for skills that need access to conversation history and loaded files.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-006          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Why use skills instead of duplicating knowledge in multiple agents?

OPTIONS:
  [A] Skills are faster
  [B] Skills provide single source of truth - update once, all agents benefit ← ✓ CORRECT
  [C] Skills are required by Claude Code
  [D] Skills cost less

ANSWER: B

EXPLANATION:
  Skills follow DRY (Don't Repeat Yourself) principles. Without skills, you'd duplicate security knowledge in Agent A, B, and C. With skills, the security-guardian skill is the single source - all agents inherit it, and updates propagate everywhere. This ensures consistency and simplifies maintenance.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-007          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What makes a GOOD skill versus a BAD skill?

OPTIONS:
  [A] Good skills are longer, bad skills are shorter
  [B] Good skills are reusable, domain-focused, and include reference material; bad skills are single-agent specific and too broad ← ✓ CORRECT
  [C] Good skills use opus, bad skills use haiku
  [D] Good skills have more files

ANSWER: B

EXPLANATION:
  Good skills are: reusable across multiple agents, domain-focused (not too broad), contain reference material and checklists, and include verification steps. Bad skills are: specific to only one agent, too broad in scope, just instructions without reference material, and missing verification checklists.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-008          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the TDD (Test-Driven Development) skill's core methodology?

OPTIONS:
  [A] Write tests after code
  [B] RED (failing test) -> GREEN (minimal code to pass) -> REFACTOR (improve while green) ← ✓ CORRECT
  [C] Write all tests first, then all code
  [D] Skip tests for speed

ANSWER: B

EXPLANATION:
  The TDD skill follows: 1) RED - write a failing test for desired behavior BEFORE code, 2) GREEN - write MINIMUM code to make the test pass, 3) REFACTOR - improve implementation while keeping tests green, then repeat. This cycle ensures tests actually verify behavior by requiring failure first, then incremental improvement.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-009          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should a Security Guardian skill include for OWASP coverage?

OPTIONS:
  [A] Just a list of vulnerabilities
  [B] Checklists for each OWASP Top 10 category with specific verification items ← ✓ CORRECT
  [C] Links to external security tools
  [D] Password examples

ANSWER: B

EXPLANATION:
  A Security Guardian skill should include detailed checklists for each OWASP Top 10 category: A01 Broken Access Control (check authorization, IDOR, privilege escalation), A02 Cryptographic Failures (hardcoded secrets, TLS, password hashing), A03 Injection (SQL, NoSQL, XSS), etc. Each category should have specific verification items with checkboxes.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-010          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'agent' field in SKILL.md frontmatter?

OPTIONS:
  [A] Which agent created the skill
  [B] Whether the skill is 'specialist' (domain-focused) or 'general' (broad) ← ✓ CORRECT
  [C] The agent that must use this skill
  [D] The agent's name

ANSWER: B

EXPLANATION:
  The `agent` field indicates whether the skill is 'specialist' (domain-focused, deep expertise in one area) or 'general' (broad, applicable across domains). Specialist skills like security-guardian provide deep domain knowledge, while general skills might provide widely-applicable patterns or utilities.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-011          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the 'allowed-tools' field in skill frontmatter control?

OPTIONS:
  [A] Tools the skill documents
  [B] Tools the skill can use when activated ← ✓ CORRECT
  [C] Tools that can activate the skill
  [D] Tools to install

ANSWER: B

EXPLANATION:
  The `allowed-tools` field specifies which tools the skill can use when activated. For example, a security-guardian skill might have `allowed-tools: Read, Grep, Bash` - allowing it to read files, search for patterns, and run security scanning commands, but not modify files. This provides security boundaries for each skill.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-012          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What optional folders can a skill directory contain?

OPTIONS:
  [A] Only SKILL.md is allowed
  [B] reference.md, checklists/, examples/, and scripts/ ← ✓ CORRECT
  [C] src/, dist/, and node_modules/
  [D] tests/, docs/, and config/

ANSWER: B

EXPLANATION:
  A skill directory can contain: SKILL.md (required), reference.md (detailed documentation), checklists/ (verification lists like security.md, performance.md), examples/ (code patterns like good-example.ts, bad-example.ts), and scripts/ (helper scripts like audit.sh). This rich structure supports comprehensive domain knowledge.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-013          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the Security Guardian skill, what is an example of GOOD password hashing?

OPTIONS:
  [A] md5(password)
  [B] sha1(password)
  [C] argon2 or bcrypt ← ✓ CORRECT
  [D] Base64 encoding

ANSWER: C

EXPLANATION:
  The Security Guardian skill shows argon2 or bcrypt as secure password hashing. BAD examples explicitly listed: md5(password) and sha1(password) - these are cryptographically broken for password storage. Good pattern: `const hashedPassword = await hash(password)` using argon2 library. Always verify password with `await verify(hashedPassword, inputPassword)`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-014          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the AAA pattern in TDD testing?

OPTIONS:
  [A] Ask, Answer, Assert
  [B] Arrange, Act, Assert ← ✓ CORRECT
  [C] Analyze, Apply, Approve
  [D] Accept, Adjust, Acknowledge

ANSWER: B

EXPLANATION:
  AAA stands for Arrange, Act, Assert: 1) Arrange - set up test data and preconditions, 2) Act - execute the code being tested, 3) Assert - verify the result matches expectations. Example: Arrange items array, Act by calling calculateTotal(items), Assert that total equals expected value. This structure makes tests readable and maintainable.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-015          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What community skill repository focuses on cybersecurity and penetration testing?

OPTIONS:
  [A] awesome-claude-skills
  [B] claude-security-pack
  [C] zebbern/claude-code-guide with 29 cybersecurity skills ← ✓ CORRECT
  [D] owasp-claude-skills

ANSWER: C

EXPLANATION:
  The zebbern/claude-code-guide repository contains 29 cybersecurity-focused skills covering: penetration testing (SQL injection, XSS, IDOR), security tools (Metasploit, Burp Suite, SQLMap), infrastructure security (AWS, Cloud, Network), and methodologies (ethical hacking, pentest checklists). Important: these should be tested thoroughly and used only with proper authorization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-016          Difficulty: junior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What should skills include to be most useful?

OPTIONS:
  [A] Only theory and concepts
  [B] Checklists, good/bad code examples, and methodology steps ← ✓ CORRECT
  [C] Links to external websites
  [D] Marketing descriptions

ANSWER: B

EXPLANATION:
  Useful skills include: methodology steps (clear process to follow), checklists (verification items with checkboxes), good/bad code examples (showing correct patterns and anti-patterns), and reference material. This combination provides both theoretical knowledge and practical guidance that agents can apply directly to tasks.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-017          Difficulty: senior               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you reference a skill in an agent's frontmatter?

OPTIONS:
  [A] import: skill-name
  [B] skills: [skill-name] ← ✓ CORRECT
  [C] use: skill-name
  [D] require: skill-name

ANSWER: B

EXPLANATION:
  Reference skills in an agent's frontmatter using the `skills` array: `skills: [security-guardian, tdd]`. This makes the agent inherit all knowledge from those skills. You can reference multiple skills, and the agent combines their expertise. The skill name matches the folder name in `.claude/skills/`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-018          Difficulty: power                │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What disclaimer applies to community cybersecurity skills?

OPTIONS:
  [A] They are officially certified
  [B] Test thoroughly, ensure authorization, verify against policies, use only legally ← ✓ CORRECT
  [C] They work on all systems
  [D] No disclaimer needed

ANSWER: B

EXPLANATION:
  Community cybersecurity skills come with important disclaimers: test thoroughly before using in production assessments, ensure you have proper authorization before penetration testing, review and validate against your organization's security policies, use only in legal contexts with written permission from system owners, and contribute back if you find issues. Verification is essential for any security tooling.
  

─────────────────────────────────────────────────────────────────

