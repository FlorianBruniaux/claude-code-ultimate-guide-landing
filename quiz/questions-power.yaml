# ═══════════════════════════════════════════════════════════════
# Claude Code Quiz - POWER Level
# ═══════════════════════════════════════════════════════════════

Total Questions: 47
Difficulty: power
Categories: 12

## Table of Contents

  AI Ecosystem: 3 questions
  Advanced Patterns: 9 questions
  Agents: 5 questions
  Architecture Internals: 2 questions
  Commands: 2 questions
  Core Concepts: 5 questions
  Hooks: 5 questions
  MCP Servers: 4 questions
  Memory & Settings: 4 questions
  Quick Start: 1 questions
  Reference: 3 questions
  Skills: 4 questions

══════════════════════════════════════════════════════════════════════


######################################################################
# CATEGORY: AI ECOSYSTEM
# 3 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-007          Category: AI Ecosystem              │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In the complete workflow pipeline, what is the correct order of phases?

OPTIONS:
  [A] Implementation -> Planning -> Delivery
  [B] Planning (Perplexity/Gemini/NotebookLM) -> Implementation (Claude Code) -> Delivery (Kimi) ← ✓ CORRECT
  [C] Delivery -> Planning -> Implementation
  [D] All tools simultaneously

ANSWER: B

EXPLANATION:
  The complete pipeline has 3 phases:
  
  PLANNING PHASE:
  - Perplexity: Deep Research -> spec.md
  - Gemini: Diagram Analysis -> mermaid + plan
  - NotebookLM: Doc Synthesis -> audio overview
  
  IMPLEMENTATION PHASE:
  - Claude Code: Multi-file implementation
  - IDE + Copilot: Inline autocomplete
  
  DELIVERY PHASE:
  - Claude Code: PR description, release notes
  - Kimi: Stakeholder deck (presentation.pptx)
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-010          Category: AI Ecosystem              │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Minimal Stack' monthly cost recommendation for AI tools?

OPTIONS:
  [A] $200+/month - all Pro subscriptions
  [B] $40-70/month - Claude Code + Perplexity Pro, free tiers for rest ← ✓ CORRECT
  [C] $0 - only free tiers
  [D] $500+/month - enterprise plans

ANSWER: B

EXPLANATION:
  Recommended subscription stacks:
  
  Minimal Stack ($40-70/month):
  - Claude Code (pay-per-use): $20-50
  - Perplexity Pro: $20
  - Everything else: Free tiers (NotebookLM, Kimi, Gemini free)
  
  Balanced Stack ($80-110/month):
  - Add Gemini Advanced ($20) and Cursor Pro ($20)
  
  Cost optimization tips:
  - Use Haiku for simple tasks
  - Batch research sessions in Perplexity
  - Check context usage regularly (/status)
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 15-012          Category: AI Ecosystem              │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 documented external orchestration systems for multi-agent Claude Code?

OPTIONS:
  [A] LangChain, AutoGPT, CrewAI
  [B] Vercel AI SDK, Fly.io Machines, Railway
  [C] Gas Town (Steve Yegge), multiclaude (dlorenc), agent-chat (Justin Abrahms) ← ✓ CORRECT
  [D] Kubernetes, Docker Compose, Terraform

ANSWER: C

EXPLANATION:
  Three documented external orchestration systems:
  
  1. **Gas Town** (Steve Yegge) - Multi-agent coordination with shared context
  2. **multiclaude** (dlorenc) - Parallel Claude Code instances with task distribution
  3. **agent-chat** (Justin Abrahms) - Inter-agent communication protocol
  
  These are community-built tools, not official Anthropic products. Each solves multi-agent coordination differently.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: ADVANCED PATTERNS
# 9 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-002          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you toggle thinking mode in Claude Code (Opus 4.5+)?

OPTIONS:
  [A] Use 'ultrathink' keyword in your prompt
  [B] Alt+T (or Option+T on macOS) ← ✓ CORRECT
  [C] --think CLI flag
  [D] /thinking command

ANSWER: B

EXPLANATION:
  With Opus 4.5 (v2.0.67+), thinking mode is enabled by default at maximum budget.
  
  **Controlling Thinking Mode:**
  | Method | Action | Persistence |
  |--------|--------|-------------|
  | **Alt+T** | Toggle on/off | Session |
  | **/config** | Enable/disable globally | Permanent |
  
  **Note**: Keywords like "ultrathink" are now cosmetic only - they no longer control thinking behavior.
  
  Use Alt+T to disable thinking for simple tasks (faster, cheaper).
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-005          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Rev the Engine' pattern?

OPTIONS:
  [A] Running tests in parallel
  [B] Multiple rounds of write-critique-improve cycles ← ✓ CORRECT
  [C] Restarting Claude Code between tasks
  [D] Using higher compute models

ANSWER: B

EXPLANATION:
  The "Rev the Engine" pattern uses multiple rounds of critique for quality:
  
  ```
  Round 1: [Initial implementation]
  Critique: [What's wrong]
  Improvement: [Better version]
  
  Round 2: [Improved implementation]
  Critique: [What's still wrong]
  Improvement: [Even better version]
  
  Round 3: [Final implementation]
  Final check: [Verification]
  ```
  
  Typically 3 rounds are recommended for quality work.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-008          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the Verify Gate Pattern before creating a PR?

OPTIONS:
  [A] Just run tests
  [B] Build -> Lint -> Test -> Type-check -> THEN create PR ← ✓ CORRECT
  [C] Create PR first, then fix issues
  [D] Manual review only

ANSWER: B

EXPLANATION:
  The Verify Gate Pattern ensures all checks pass before PR creation:
  
  ```
  Build -> Lint -> Test -> Type-check -> THEN create PR
  ```
  
  If ANY step fails:
  - Stop immediately
  - Report what failed and why
  - Suggest fixes
  - Do NOT proceed to PR creation
  
  This prevents wasted CI cycles and review time.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-010          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  According to 'Continuous Improvement Mindset', what should you ask after every manual intervention?

OPTIONS:
  [A] Was this my fault?
  [B] How can I improve the process so this error can be avoided next time? ← ✓ CORRECT
  [C] Who is responsible for this?
  [D] Should I use a different AI?

ANSWER: B

EXPLANATION:
  After every manual intervention, ask:
  "How can I improve the process so this error or manual fix can be avoided next time?"
  
  The improvement pipeline:
  1. Can a linting rule catch it? -> Add lint rule
  2. Can it go in conventions/docs? -> Add to CLAUDE.md or ADRs
  3. Neither? -> Accept as edge case
  
  The meta-skill: instead of fixing code, fix the system that produces the code.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-013          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When should you NOT use --dangerously-skip-permissions?

OPTIONS:
  [A] In CI/CD pipelines
  [B] On production systems or sensitive codebases ← ✓ CORRECT
  [C] For automated testing
  [D] In Docker containers

ANSWER: B

EXPLANATION:
  Never use `--dangerously-skip-permissions` on production systems or sensitive codebases.
  
  Safe usage:
  - CI/CD pipelines with isolated environments
  - Automated testing with limited scope
  - Development containers
  
  Unsafe usage:
  - Production systems
  - Codebases with secrets
  - Environments with sensitive data
  
  The flag bypasses all permission prompts, creating security risks.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-016          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What git workflow enables working on multiple features simultaneously with isolated contexts?

OPTIONS:
  [A] Git stash
  [B] Git worktrees ← ✓ CORRECT
  [C] Git branches only
  [D] Git submodules

ANSWER: B

EXPLANATION:
  Git worktrees create multiple working directories from the same repository.
  
  Benefits:
  - Work on multiple features simultaneously
  - Each worktree has independent Claude Code context
  - No need for stash/switch operations
  - Parallel testing while developing
  
  ```bash
  git worktree add ../myproject-hotfix hotfix
  git worktree add ../myproject-feature-a feature-a
  ```
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-022          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 5 layers of 'Mechanic Stacking'?

OPTIONS:
  [A] Plan Mode, Extended Thinking, Rev the Engine, Split-Role, Permutation ← ✓ CORRECT
  [B] Plan Mode, Sequential Thinking, Context7, Serena, Playwright
  [C] CLAUDE.md, Plan Mode, Extended Thinking, MCP Servers, Hooks
  [D] Plan Mode, Extended Thinking, Rev the Engine, Multi-Agent, Hooks

ANSWER: A

EXPLANATION:
  Mechanic Stacking layers 5 techniques for maximum Claude Code power:
  
  1. **Plan Mode** - Safe exploration without changes
  2. **Extended Thinking** - Deep internal reasoning
  3. **Rev the Engine** - Progressive warm-up prompts
  4. **Split-Role** - Separate architect/implementer/reviewer
  5. **Permutation** - Systematic variation testing
  
  Each layer compounds the previous one's effectiveness.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-023          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a 'Permutation Framework' in Claude Code?

OPTIONS:
  [A] A/B testing of UI variants
  [B] CLAUDE.md-driven systematic variation testing: define dimensions, generate variants, implement, evaluate ← ✓ CORRECT
  [C] Random code generation for benchmarks
  [D] Automated regression test suite

ANSWER: B

EXPLANATION:
  A Permutation Framework uses CLAUDE.md to drive systematic variation testing. The workflow: define variation dimensions (e.g., algorithm choice, data structure, caching strategy), generate all combinations, implement each variant, evaluate with metrics. This ensures you explore the solution space methodically rather than picking the first approach.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 09-027          Category: Advanced Patterns         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 specialized agents in multi-agent code review?

OPTIONS:
  [A] Security Reviewer, Performance Analyst, UX Reviewer
  [B] Linter, Type Checker, Test Runner
  [C] Consistency Auditor, SOLID Analyst, Defensive Code Auditor ← ✓ CORRECT
  [D] Junior Reviewer, Senior Reviewer, Architect Reviewer

ANSWER: C

EXPLANATION:
  Multi-agent PR review uses 3 specialized agents:
  
  1. **Consistency Auditor** - Checks naming conventions, import patterns, code style adherence
  2. **SOLID Analyst** - Reviews architectural principles, dependency injection, single responsibility
  3. **Defensive Code Auditor** - Validates error handling, input validation, edge cases
  
  Each agent has anti-hallucination safeguards (occurrence rule, file-scoped claims).
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: AGENTS
# 5 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-006          Category: Agents                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Tool SEO' in agent design?

OPTIONS:
  [A] Making tools searchable online
  [B] Optimizing the description field to improve when Claude auto-activates the agent ← ✓ CORRECT
  [C] SEO for documentation
  [D] A marketing technique

ANSWER: B

EXPLANATION:
  Tool SEO optimizes the agent's description field to improve auto-activation. Techniques include: using "use PROACTIVELY" to encourage automatic activation, listing explicit trigger keywords, describing specific contexts, and adding short nicknames. A good description: "Security code reviewer - use PROACTIVELY when: reviewing auth code, analyzing API endpoints... Triggers: security, auth, vulnerability, OWASP"
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-009          Category: Agents                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the '7-Parallel-Task Method'?

OPTIONS:
  [A] Running 7 Claude instances simultaneously
  [B] Launching 7 specialized sub-agents in parallel to implement complete features ← ✓ CORRECT
  [C] A debugging technique
  [D] A code review checklist

ANSWER: B

EXPLANATION:
  The 7-Parallel-Task Method launches 7 specialized sub-agents in parallel: 1) Components, 2) Styles, 3) Tests, 4) Types, 5) Hooks, 6) Integration, 7) Config. All run in parallel, then results are consolidated. This dramatically speeds up feature implementation by parallelizing independent work streams.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-011          Category: Agents                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  In multi-agent orchestration, what model combination is recommended?

OPTIONS:
  [A] Opus everywhere for quality
  [B] Haiku everywhere for cost savings
  [C] Sonnet orchestrator + Haiku workers + Sonnet validator ← ✓ CORRECT
  [D] Use the same model for all agents

ANSWER: C

EXPLANATION:
  The recommended pattern is: Sonnet as orchestrator (coordinates), Haiku workers (parallel execution), Sonnet validator (final check). This is 2-2.5x cheaper than using Opus everywhere with equivalent quality for 90% of tasks. For example, refactoring 100 files: Sonnet analyzes and plans, Haiku does parallel edits, Sonnet validates - saving 80-90% cost.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-014          Category: Agents                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Split Role Sub-Agents' pattern?

OPTIONS:
  [A] Dividing one agent into multiple files
  [B] Multi-perspective analysis using parallel agents with different expert roles ← ✓ CORRECT
  [C] Splitting code review into phases
  [D] Assigning agents to different team members

ANSWER: B

EXPLANATION:
  Split Role Sub-Agents provide multi-perspective analysis in parallel. Process: 1) Activate Plan Mode (thinking enabled by default in Opus 4.5), 2) Ask "What expert roles would analyze this?", 3) Select roles (e.g., Security Expert, Senior Dev, Code Reviewer), 4) Run parallel analysis from each perspective, 5) Consolidate reports into recommendations. Great for comprehensive code and UX reviews.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 04-018          Category: Agents                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the invocation reliability difference between AGENTS.md (eager context) and Skills (lazy invocation)?

OPTIONS:
  [A] Skills are more reliable than AGENTS.md
  [B] Both have 100% reliability
  [C] AGENTS.md: 100% reliable (always loaded) vs Skills: 53-79% auto-invoked ← ✓ CORRECT
  [D] AGENTS.md is deprecated in favor of Skills

ANSWER: C

EXPLANATION:
  AGENTS.md uses eager context loading - always present in Claude's context, so 100% reliable activation. Skills use lazy invocation - auto-detected and invoked only when Claude recognizes the need, achieving 53-79% auto-invocation rate. Trade-off: AGENTS.md costs context tokens on every session, Skills save tokens but may miss activations. Use AGENTS.md for critical behaviors, Skills for optional capabilities.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: ARCHITECTURE INTERNALS
# 2 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-014          Category: Architecture Internals    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the API cost overhead of fetching full details for 50 tasks via Tasks API?

OPTIONS:
  [A] 10x overhead (10 API calls)
  [B] 25x overhead (25 API calls)
  [C] 51x overhead (1 TaskList + 50 TaskGet calls required) ← ✓ CORRECT
  [D] 100x overhead (100 API calls)

ANSWER: C

EXPLANATION:
  Tasks API limitation: TaskList returns only summary fields (id, subject, status, owner, blockedBy). To get full details (description, metadata), you need individual TaskGet calls. For 50 tasks: 1 TaskList + 50 TaskGet = 51 API calls. This N+1 pattern is a known limitation compared to TodoWrite which returned everything in one call.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 12-015          Category: Architecture Internals    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is TeammateTool and what is its status?

OPTIONS:
  [A] Production-ready multi-agent framework
  [B] Experimental multi-agent coordination (spawnTeam, discoverTeams, requestJoin, approveJoin) - unstable, no official support ← ✓ CORRECT
  [C] Official Anthropic tool for team collaboration
  [D] Deprecated feature replaced by Tasks API

ANSWER: B

EXPLANATION:
  TeammateTool is an experimental multi-agent coordination tool with 4 operations: spawnTeam, discoverTeams, requestJoin, approveJoin. Status: unstable, not officially supported by Anthropic. It allows Claude instances to form teams and coordinate, but the API is subject to change without notice. Not recommended for production use.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: COMMANDS
# 2 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-008          Category: Commands                  │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What technique does the Problem Framer command use to find root causes?

OPTIONS:
  [A] SWOT Analysis
  [B] 5 Whys Analysis ← ✓ CORRECT
  [C] Pareto Analysis
  [D] Fishbone Diagram

ANSWER: B

EXPLANATION:
  The Problem Framer command uses the "5 Whys Analysis" technique.
  
  This involves asking "Why?" five times to drill down to the root cause:
  - Why 1: First answer
  - Why 2: Deeper answer
  - Why 3: Even deeper
  - Why 4: Getting to root
  - Why 5: Root cause
  
  The command then reframes the problem as: "How might we [action] for [user] so that [outcome]?"
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 06-011          Category: Commands                  │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended order of git commands in a PR creation workflow?

OPTIONS:
  [A] push, diff, create PR
  [B] status, branch, log, diff, push if needed, create PR ← ✓ CORRECT
  [C] add, commit, push, create PR
  [D] checkout, status, push, create PR

ANSWER: B

EXPLANATION:
  The recommended PR workflow order is:
  
  1. `git status` - Verify clean working directory
  2. `git branch` - Confirm on feature branch
  3. `git log main..HEAD` - Review all commits
  4. `git diff main...HEAD` - See all changes vs main
  5. `git push -u origin [branch]` - Push if not already pushed
  6. `gh pr create` - Create the PR
  
  This thorough process ensures quality PRs with proper context.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: CORE CONCEPTS
# 5 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-006          Category: Core Concepts             │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Last 20% Rule' in context management?

OPTIONS:
  [A] Always keep the last 20% of your conversation
  [B] Reserve ~20% of context for multi-file operations, corrections, and summary generation at session end ← ✓ CORRECT
  [C] Delete 20% of context regularly
  [D] Use only 20% of available context

ANSWER: B

EXPLANATION:
  The Last 20% Rule recommends reserving approximately 20% of your context for: multi-file operations at end of session, last-minute corrections, and generating summary/checkpoint documents. This buffer ensures you can complete your work properly even as context fills up.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-010          Category: Core Concepts             │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is OpusPlan mode?

OPTIONS:
  [A] A premium subscription tier
  [B] Using Opus for planning (superior reasoning) and Sonnet for implementation (cost-efficient) ← ✓ CORRECT
  [C] A debugging mode
  [D] A way to plan without Claude

ANSWER: B

EXPLANATION:
  OpusPlan uses Opus for planning (with superior reasoning capabilities) and automatically switches to Sonnet for implementation (more cost-efficient). Enable with `/model opusplan`. This provides Opus-quality planning while preserving tokens through Sonnet-speed execution. Particularly valuable for Pro subscribers with limited Opus tokens.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-014          Category: Core Concepts             │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the purpose of the 'Sanity Check Technique'?

OPTIONS:
  [A] To verify code compiles correctly
  [B] To verify Claude has loaded your CLAUDE.md configuration correctly ← ✓ CORRECT
  [C] To check for memory leaks
  [D] To validate test coverage

ANSWER: B

EXPLANATION:
  The Sanity Check Technique verifies Claude loaded your configuration. Add identifiable info to CLAUDE.md (like your name, project name, tech stack), then ask Claude "What is my name? What project am I working on?" Correct answers confirm configuration is loaded. For advanced checking, add multiple checkpoints throughout long CLAUDE.md files.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-016          Category: Core Concepts             │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is a 'Session Handoff Pattern' used for?

OPTIONS:
  [A] Transferring sessions between team members
  [B] Documenting state, decisions, and next steps to maintain continuity between sessions ← ✓ CORRECT
  [C] Backing up your code
  [D] Exporting conversation history

ANSWER: B

EXPLANATION:
  The Session Handoff Pattern creates a document to bridge gaps between sessions. It includes: what was accomplished, current state, decisions made, next steps, and context for the next session. Create handoffs at end of work day, before context limit, when switching focus areas, or during interruptions. Store in `claudedocs/handoffs/handoff-YYYY-MM-DD.md`.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 02-018          Category: Core Concepts             │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is Auto Plan Mode and how do you enable it?

OPTIONS:
  [A] Automatic planning that's always on by default
  [B] A configuration that forces Claude to present a plan and wait for approval before any tool execution ← ✓ CORRECT
  [C] A mode that automatically generates project plans
  [D] A premium feature for enterprise users

ANSWER: B

EXPLANATION:
  Auto Plan Mode makes Claude present a plan and wait for explicit user approval before executing ANY tool. Configure via `~/.claude/auto-plan-mode.txt` and launch with `claude --append-system-prompt "$(cat ~/.claude/auto-plan-mode.txt)"`. Results in 76% fewer tokens with better results because plans are validated before execution.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: HOOKS
# 5 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-005          Category: Hooks                     │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the best use case for the `UserPromptSubmit` hook event?

OPTIONS:
  [A] Blocking dangerous commands
  [B] Auto-formatting code
  [C] Adding context like git status to every prompt ← ✓ CORRECT
  [D] Playing notification sounds

ANSWER: C

EXPLANATION:
  The `UserPromptSubmit` event is ideal for context enrichment.
  
  Use cases:
  - **UserPromptSubmit**: Add context (git status, current branch, staged files)
  - **PreToolUse**: Security validation (block dangerous commands)
  - **PostToolUse**: Formatting, logging, quality checks
  - **Notification**: Sound alerts, desktop notifications
  
  The context enricher example adds git branch, last commit, and staged/unstaged info.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-008          Category: Hooks                     │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What JSON structure should a hook return to send a message back to Claude?

OPTIONS:
  [A] {"message": "text"}
  [B] {"systemMessage": "text", "hookSpecificOutput": {...}} ← ✓ CORRECT
  [C] {"response": "text"}
  [D] {"output": "text"}

ANSWER: B

EXPLANATION:
  Hooks return JSON on stdout with specific fields:
  
  ```json
  {
    "systemMessage": "Message shown to Claude",
    "hookSpecificOutput": {
      "additionalContext": "Extra information"
    }
  }
  ```
  
  - `systemMessage`: Displayed to Claude as context
  - `hookSpecificOutput`: Additional structured data
  
  This allows hooks to provide context that Claude can use in its responses.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-011          Category: Hooks                     │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How do you test a security hook before deploying it?

OPTIONS:
  [A] Run Claude Code and hope it works
  [B] Pipe test JSON to the hook script and check the exit code ← ✓ CORRECT
  [C] Deploy to production and monitor
  [D] Security hooks cannot be tested

ANSWER: B

EXPLANATION:
  Test hooks by piping JSON input and checking the exit code:
  
  ```bash
  # Test with a blocked command
  echo '{"tool_name":"Bash","tool_input":{"command":"rm -rf /"}}' | ./hooks/security-blocker.sh
  echo "Exit code: $?"  # Should be 2
  
  # Test with a safe command
  echo '{"tool_name":"Bash","tool_input":{"command":"git status"}}' | ./hooks/security-blocker.sh
  echo "Exit code: $?"  # Should be 0
  ```
  
  This ensures your hook correctly blocks dangerous commands before deployment.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-013          Category: Hooks                     │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the activity logger hook example use to store logs?

OPTIONS:
  [A] SQLite database
  [B] Plain text files
  [C] JSONL (JSON Lines) files ← ✓ CORRECT
  [D] CSV files

ANSWER: C

EXPLANATION:
  The activity logger hook stores logs in JSONL format (JSON Lines).
  
  Key features:
  - Logs to `~/.claude/logs/activity-YYYY-MM-DD.jsonl`
  - Each entry contains timestamp, tool name, and session ID
  - Auto-cleanup of logs older than 7 days
  - Uses `jq` for JSON construction
  
  JSONL is ideal for log files as each line is a valid JSON object,
  making it easy to append and parse.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 07-016          Category: Hooks                     │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What are the 3 limitations of async hooks compared to sync hooks?

OPTIONS:
  [A] Can't access stdin, can't write files, can't read environment variables
  [B] No exit code feedback (can't block), no additionalContext returned, no blocking capability ← ✓ CORRECT
  [C] Can't use network, can't spawn processes, can't read files
  [D] Limited to 1s timeout, no stderr capture, no argument passing

ANSWER: B

EXPLANATION:
  Async hooks trade control for speed:
  
  1. **No exit code feedback** - Can't block Claude based on success/failure
  2. **No additionalContext** - Can't inject context back into the conversation
  3. **No blocking capability** - Fire-and-forget only
  
  Use async for non-critical operations (logging, telemetry). Use sync for security gates, formatting, and validation.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: MCP SERVERS
# 4 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-004          Category: MCP Servers               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Which MCP server provides persistent memory across sessions?

OPTIONS:
  [A] Context7
  [B] Postgres
  [C] Serena ← ✓ CORRECT
  [D] Sequential Thinking

ANSWER: C

EXPLANATION:
  Serena provides session memory that persists across conversations.
  
  Serena memory tools:
  - `write_memory` - Save context for future sessions
  - `read_memory` - Retrieve saved context
  - `list_memories` - List all stored memories
  
  Memory is stored in `.serena/memories/` and survives between Claude Code sessions.
  This is crucial for maintaining context on long-running projects.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-007          Category: MCP Servers               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  How can MCP servers work together effectively?

OPTIONS:
  [A] They cannot - only one server at a time
  [B] Context7 for patterns -> Serena for code -> Sequential for analysis -> Playwright for testing ← ✓ CORRECT
  [C] All servers must be configured identically
  [D] Servers must be chained in alphabetical order

ANSWER: B

EXPLANATION:
  MCP servers can be combined for powerful workflows:
  
  1. **Context7** - Get official pattern for auth
  2. **Serena** - Find existing auth code in codebase
  3. **Sequential** - Analyze how to integrate
  4. **Playwright** - Test the implementation
  
  This combination leverages each server's strengths for comprehensive development.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-010          Category: MCP Servers               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What distinguishes a Plugin from an MCP Server in Claude Code?

OPTIONS:
  [A] Plugins are faster
  [B] Plugins bundle Claude-specific workflows; MCP servers add external tool capabilities ← ✓ CORRECT
  [C] They are identical
  [D] MCP servers are for beginners, plugins for experts

ANSWER: B

EXPLANATION:
  The rule of thumb:
  - **Plugin** = "How Claude thinks" (new workflows, specialized agents)
  - **MCP Server** = "What Claude can do" (new tools, external systems)
  
  Plugins bundle agents, skills, and configuration into installable modules.
  MCP servers add external capabilities like database access or browser automation.
  
  Installation differs too:
  - Plugins: `claude plugin install`
  - MCP: Add to `settings.json` MCP config
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 08-013          Category: MCP Servers               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is grepai's key differentiator compared to Serena?

OPTIONS:
  [A] It's faster
  [B] It provides semantic search by intent plus call graph analysis ← ✓ CORRECT
  [C] It supports more languages
  [D] It has better documentation

ANSWER: B

EXPLANATION:
  grepai excels at intent-based search using natural language, plus offers
  call graph analysis to trace function dependencies:
  
  ```bash
  # Semantic search (finds code by meaning, not exact text)
  grepai search "user authentication flow"
  
  # Who calls this function?
  grepai trace callers "createSession"
  ```
  
  While Serena focuses on symbol-level analysis, grepai finds code by
  describing what it does and traces caller/callee relationships.
  
  Use grepai for exploring unfamiliar codebases or understanding dependencies.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: MEMORY & SETTINGS
# 4 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-006          Category: Memory & Settings         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the 'Single Source of Truth Pattern' for multi-tool AI setups?

OPTIONS:
  [A] Use only one AI tool per project
  [B] Store conventions in docs/conventions/ and reference them from all AI tool configs ← ✓ CORRECT
  [C] Copy the same rules to each AI tool's config
  [D] Let each AI tool define its own rules

ANSWER: B

EXPLANATION:
  The Single Source of Truth Pattern stores conventions in `/docs/conventions/` (coding-standards.md, architecture.md, testing.md, etc.) and references them from CLAUDE.md, CodeRabbit, and other tools. This prevents conflicts where one tool approves code that another flags. All tools enforce the same standards from one source.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-009          Category: Memory & Settings         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is 'Dynamic Memory' (Profile Switching)?

OPTIONS:
  [A] Claude's ability to remember across sessions
  [B] Temporarily modifying CLAUDE.md for specific tasks, then restoring ← ✓ CORRECT
  [C] Automatic memory compression
  [D] Syncing memory between devices

ANSWER: B

EXPLANATION:
  Dynamic Memory means temporarily modifying CLAUDE.md for specific tasks then restoring it. Techniques include: git stash (stash original, modify, restore), profile library (keep profiles like security-audit.md, debugging.md in ~/.claude/profiles/), or parallel instances (different CLAUDE.md in different worktrees). Switch profiles with a script: `claude-profile security-audit`.
  

OFFICIAL DOC: https://code.claude.com/docs/en/permissions

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-012          Category: Memory & Settings         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does 'allowedTools' configuration do differently from permission categories?

OPTIONS:
  [A] Nothing, they are the same
  [B] Provides granular control with tool-specific patterns in .claude/settings.json ← ✓ CORRECT
  [C] Only works for MCP tools
  [D] Requires admin privileges

ANSWER: B

EXPLANATION:
  The allowedTools configuration in .claude/settings.json or .claude/settings.local.json provides granular control with specific patterns. For example: 'Read(*)' allows all reads, 'Bash(git status *)' allows git status commands, 'Bash(pnpm *)' allows pnpm commands. You can set progressive permission levels from beginner (very restrictive) to advanced. Never use --dangerously-skip-permissions.

OFFICIAL DOC: https://code.claude.com/docs/en/permissions

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 03-015          Category: Memory & Settings         │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  Why should you NEVER use --dangerously-skip-permissions?

OPTIONS:
  [A] It's deprecated
  [B] It can lead to destructive operations like rm -rf, force push to main, or DROP TABLE ← ✓ CORRECT
  [C] It costs more
  [D] It's slower

ANSWER: B

EXPLANATION:
  Never use --dangerously-skip-permissions because it can lead to destructive operations. Horror stories include: `rm -rf node_modules` followed by `rm -rf .` (path error), `git push --force` to main unintentionally, `DROP TABLE users` in poorly generated migrations, and deletion of .env files with credentials. Always prefer granular allowedTools instead.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: QUICK START
# 1 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 01-012          Category: Quick Start               │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended rule of thumb for choosing between Claude Code and autocomplete tools based on code size?

OPTIONS:
  [A] <10 lines: autocomplete, >10 lines: Claude Code
  [B] <5 lines: autocomplete, 5-50 lines single file: either, >50 lines or multi-file: Claude Code ← ✓ CORRECT
  [C] Always use Claude Code regardless of size
  [D] <20 lines: autocomplete, >20 lines: Claude Code

ANSWER: B

EXPLANATION:
  The guide provides clear guidance: less than 5 lines of code - use Copilot/autocomplete; 5-50 lines in a single file - either tool works; more than 50 lines or multi-file changes - use Claude Code. This helps you choose the right tool for the task's complexity level.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: REFERENCE
# 3 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-009          Category: Reference                 │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  If an MCP server name validation fails with pattern error, what characters ARE allowed?

OPTIONS:
  [A] Letters only
  [B] Letters, numbers, underscores, hyphens (max 64 chars) ← ✓ CORRECT
  [C] Any characters except spaces
  [D] Alphanumeric and periods

ANSWER: B

EXPLANATION:
  MCP server names must match: `^[a-zA-Z0-9_-]{1,64}`
  
  Allowed:
  - Letters (a-z, A-Z)
  - Numbers (0-9)
  - Underscores (_)
  - Hyphens (-)
  - Maximum 64 characters
  
  Not allowed:
  - Spaces
  - Special characters (@, #, etc.)
  - More than 64 characters
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-014          Category: Reference                 │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the recommended .gitignore pattern for Claude Code files?

OPTIONS:
  [A] Ignore all .claude/ contents
  [B] Ignore settings.local.json and CLAUDE.local.md, keep agents/commands/hooks ← ✓ CORRECT
  [C] Don't ignore anything
  [D] Ignore only agents/

ANSWER: B

EXPLANATION:
  Recommended .gitignore:
  
  ```gitignore
  # Claude Code - Personal (ignore)
  .claude/settings.local.json
  CLAUDE.local.md
  .claude/.serena/
  
  # Claude Code - Team (keep/commit)
  # .claude/CLAUDE.md (project memory)
  # .claude/agents/
  # .claude/commands/
  # .claude/hooks/
  # .claude/settings.json
  ```
  
  This keeps team workflows shared while personal settings stay private.

OFFICIAL DOC: https://code.claude.com/docs/en/memory

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 10-017          Category: Reference                 │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  When Sequential Thinking MCP seems slow or unresponsive, what should you expect?

OPTIONS:
  [A] It's broken and needs restart
  [B] 10-30 second responses are normal due to significant compute ← ✓ CORRECT
  [C] Switch to a different MCP
  [D] Reduce the query complexity

ANSWER: B

EXPLANATION:
  Sequential Thinking uses significant compute - expect 10-30 second responses.
  
  This is not an error, just be patient.
  
  Tips for Sequential:
  - Works best with specific, well-defined problems
  - Good: "Debug why user authentication fails on mobile"
  - Bad: "Make the app better"
  
  The longer response time reflects deeper analysis.
  

─────────────────────────────────────────────────────────────────


######################################################################
# CATEGORY: SKILLS
# 4 questions
######################################################################

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-008          Category: Skills                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What is the TDD (Test-Driven Development) skill's core methodology?

OPTIONS:
  [A] Write tests after code
  [B] RED (failing test) -> GREEN (minimal code to pass) -> REFACTOR (improve while green) ← ✓ CORRECT
  [C] Write all tests first, then all code
  [D] Skip tests for speed

ANSWER: B

EXPLANATION:
  The TDD skill follows: 1) RED - write a failing test for desired behavior BEFORE code, 2) GREEN - write MINIMUM code to make the test pass, 3) REFACTOR - improve implementation while keeping tests green, then repeat. This cycle ensures tests actually verify behavior by requiring failure first, then incremental improvement.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-011          Category: Skills                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What does the 'allowed-tools' field in skill frontmatter control?

OPTIONS:
  [A] Tools the skill documents
  [B] Tools the skill can use when activated ← ✓ CORRECT
  [C] Tools that can activate the skill
  [D] Tools to install

ANSWER: B

EXPLANATION:
  The `allowed-tools` field specifies which tools the skill can use when activated. For example, a security-guardian skill might have `allowed-tools: Read, Grep, Bash` - allowing it to read files, search for patterns, and run security scanning commands, but not modify files. This provides security boundaries for each skill.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-015          Category: Skills                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What community skill repository focuses on cybersecurity and penetration testing?

OPTIONS:
  [A] awesome-claude-skills
  [B] claude-security-pack
  [C] zebbern/claude-code-guide with 29 cybersecurity skills ← ✓ CORRECT
  [D] owasp-claude-skills

ANSWER: C

EXPLANATION:
  The zebbern/claude-code-guide repository contains 29 cybersecurity-focused skills covering: penetration testing (SQL injection, XSS, IDOR), security tools (Metasploit, Burp Suite, SQLMap), infrastructure security (AWS, Cloud, Network), and methodologies (ethical hacking, pentest checklists). Important: these should be tested thoroughly and used only with proper authorization.
  

─────────────────────────────────────────────────────────────────

┌─────────────────────────────────────────────────────────────┐
│ ID: 05-018          Category: Skills                    │
└─────────────────────────────────────────────────────────────┘

QUESTION:
  What disclaimer applies to community cybersecurity skills?

OPTIONS:
  [A] They are officially certified
  [B] Test thoroughly, ensure authorization, verify against policies, use only legally ← ✓ CORRECT
  [C] They work on all systems
  [D] No disclaimer needed

ANSWER: B

EXPLANATION:
  Community cybersecurity skills come with important disclaimers: test thoroughly before using in production assessments, ensure you have proper authorization before penetration testing, review and validate against your organization's security policies, use only in legal contexts with written permission from system owners, and contribute back if you find issues. Verification is essential for any security tooling.
  

─────────────────────────────────────────────────────────────────

